import time
import requests
from dotenv import load_dotenv
import os

load_dotenv()

class Instagram:
    def __init__(self):
        """Instagram ë°ì´í„° ìˆ˜ì§‘ í´ë˜ìŠ¤ ì´ˆê¸°í™”"""
        self.api_key = os.getenv("BRIGHTDATA_API_KEY")
        if not self.api_key:
            raise ValueError("BRIGHTDATA_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def trigger_snapshot_request(self, dataset_id, params, data, max_retries=3):
        """ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘ ìš”ì²­ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        url = "https://api.brightdata.com/datasets/v3/trigger"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }
        full_params = {"dataset_id": dataset_id, **params}
        
        for attempt in range(max_retries):
            try:
                print(f"ğŸ”„ API ìš”ì²­ ì‹œë„ {attempt + 1}/{max_retries}")
                response = requests.post(url, headers=headers, params=full_params, json=data, timeout=30)

                print(f"ğŸ” API ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status_code}")
                print(f"ğŸ” API ì‘ë‹µ í—¤ë”: {dict(response.headers)}")
                print(f"ğŸ” API ì‘ë‹µ í…ìŠ¤íŠ¸: {response.text[:500]}...")  # ì²˜ìŒ 500ìë§Œ ì¶œë ¥

                # 502 Bad Gateway ì˜¤ë¥˜ ì²˜ë¦¬
                if response.status_code == 502:
                    print(f"âŒ 502 Bad Gateway ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{max_retries})")
                    if attempt < max_retries - 1:
                        wait_time = (attempt + 1) * 10  # 10ì´ˆ, 20ì´ˆ, 30ì´ˆ ëŒ€ê¸°
                        print(f"â³ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                        time.sleep(wait_time)
                        continue
                    else:
                        raise Exception(f"502 Bad Gateway ì˜¤ë¥˜ê°€ {max_retries}ë²ˆ ì—°ì† ë°œìƒí–ˆìŠµë‹ˆë‹¤. BrightData ì„œë²„ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                
                # 5xx ì„œë²„ ì˜¤ë¥˜ ì²˜ë¦¬
                if response.status_code >= 500:
                    print(f"âŒ ì„œë²„ ì˜¤ë¥˜ {response.status_code} (ì‹œë„ {attempt + 1}/{max_retries})")
                    if attempt < max_retries - 1:
                        wait_time = (attempt + 1) * 5
                        print(f"â³ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                        time.sleep(wait_time)
                        continue
                    else:
                        raise Exception(f"ì„œë²„ ì˜¤ë¥˜ {response.status_code}ê°€ {max_retries}ë²ˆ ì—°ì† ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                
                # 4xx í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜ëŠ” ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
                if response.status_code >= 400:
                    raise Exception(f"í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜ {response.status_code}: {response.text}")

                try:
                    result = response.json()
                    snapshot_id = result.get("snapshot_id")
                    if not snapshot_id:
                        print(f"âŒ snapshot_idê°€ ì‘ë‹µì— ì—†ìŒ. ì „ì²´ ì‘ë‹µ: {result}")
                        raise ValueError("snapshot_id not found in response.")
                    print(f"âœ… ìŠ¤ëƒ…ìƒ· ID íšë“: {snapshot_id}")
                    return snapshot_id
                except requests.exceptions.JSONDecodeError as e:
                    print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                    print(f"âŒ ì‘ë‹µ í…ìŠ¤íŠ¸: {response.text}")
                    if attempt < max_retries - 1:
                        print(f"â³ 5ì´ˆ í›„ ì¬ì‹œë„...")
                        time.sleep(5)
                        continue
                    else:
                        raise Exception(f"Failed to parse trigger response as JSON. Status: {response.status_code}, Response: {response.text}")
                        
            except requests.exceptions.Timeout:
                print(f"âŒ ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ì‹œë„ {attempt + 1}/{max_retries})")
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 5
                    print(f"â³ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(wait_time)
                    continue
                else:
                    raise Exception(f"ìš”ì²­ì´ {max_retries}ë²ˆ ì—°ì† íƒ€ì„ì•„ì›ƒë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            except requests.exceptions.RequestException as e:
                print(f"âŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e} (ì‹œë„ {attempt + 1}/{max_retries})")
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 5
                    print(f"â³ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(wait_time)
                    continue
                else:
                    raise Exception(f"ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ê°€ {max_retries}ë²ˆ ì—°ì† ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        
        raise Exception(f"ëª¨ë“  ì¬ì‹œë„ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤ ({max_retries}ë²ˆ ì‹œë„)")

    def wait_for_snapshot(self, snapshot_id, account_count=1, data_type="profile"):
        """ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘ ì™„ë£Œ ëŒ€ê¸° ë° ë°ì´í„° ìœ„ì¹˜ í™•ì¸"""
        url = f"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}"
        headers = {"Authorization": f"Bearer {self.api_key}"}
        params = {"format": "json"}

        # ê¸°ë³¸ 1ë¶„ + ê³„ì • ìˆ˜ì— ë”°ë¥¸ ì¶”ê°€ ëŒ€ê¸° ì‹œê°„
        base_wait_time = 60  # ê¸°ë³¸ 1ë¶„
        
        if data_type in ["post", "reel"]:
            # ê²Œì‹œê¸€ê³¼ ë¦´ìŠ¤: ê³„ì • 1ê°œë‹¹ 30ì´ˆì”© ì¶”ê°€
            additional_wait_time = account_count * 30
        else:
            # í”„ë¡œí•„: ê³„ì • 1ê°œë‹¹ 1ì´ˆì”© ì¶”ê°€
            additional_wait_time = account_count
        
        initial_wait_time = base_wait_time + additional_wait_time
        
        # ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ ì„¤ì •
        if data_type in ["post", "reel"]:
            # ê²Œì‹œê¸€ê³¼ ë¦´ìŠ¤: ê¸°ë³¸ 5ë¶„ + ê³„ì • ìˆ˜ë§Œí¼ 30ì´ˆì”© ì¶”ê°€
            max_wait_time = 300 + (account_count * 30)
        else:
            # í”„ë¡œí•„: ê¸°ë³¸ 5ë¶„ + ê³„ì • ìˆ˜ë§Œí¼ 1ì´ˆì”© ì¶”ê°€
            max_wait_time = 300 + account_count
        
        print(f"â° ìŠ¤ëƒ…ìƒ· ëŒ€ê¸° ì‹œì‘: ì´ˆê¸° ëŒ€ê¸° {initial_wait_time}ì´ˆ, ìµœëŒ€ ëŒ€ê¸° {max_wait_time}ì´ˆ")
        
        # ì´ˆê¸° ëŒ€ê¸° ì‹œê°„
        print(f"â³ ì´ˆê¸° ëŒ€ê¸° ì¤‘... ({initial_wait_time}ì´ˆ)")
        time.sleep(initial_wait_time)
        
        wait_count = initial_wait_time
        consecutive_202_count = 0  # ì—°ì† 202 ì‘ë‹µ ì¹´ìš´íŠ¸
        
        while wait_count < max_wait_time:
            try:
                response = requests.get(url, headers=headers, params=params, timeout=30)
                print("Status Code:", response.status_code)

                if response.status_code == 202:
                    consecutive_202_count += 1
                    print(f"Still processing. Waiting 30 seconds... (ì—°ì† {consecutive_202_count}ë²ˆ)")
                    time.sleep(30)
                    wait_count += 30
                    continue

                if response.status_code != 200:
                    print(f"Unexpected status code: {response.status_code}")
                    if response.status_code >= 500:
                        print("ì„œë²„ ì˜¤ë¥˜ë¡œ ì¸í•œ ëŒ€ê¸° ì‹œê°„ ì—°ì¥...")
                        time.sleep(60)  # ì„œë²„ ì˜¤ë¥˜ ì‹œ ë” ì˜¤ë˜ ëŒ€ê¸°
                        wait_count += 60
                    else:
                        time.sleep(30)
                        wait_count += 30
                    continue

                result = response.json()
                print(f"ğŸ” Snapshot ì‘ë‹µ êµ¬ì¡°: {type(result)}")
                if isinstance(result, dict):
                    print(f"ğŸ” Snapshot ì‘ë‹µ í‚¤: {list(result.keys())}")
                    if "file_urls" in result:
                        print(f"ğŸ” file_urls íƒ€ì…: {type(result['file_urls'])}, ë‚´ìš©: {result['file_urls']}")

                if isinstance(result, list):
                    print("Snapshot returned data directly.")
                    return {"type": "direct_data", "data": result}

                if result.get("status") == "done":
                    file_urls = result.get("file_urls", [])
                    if not file_urls:
                        raise Exception("Snapshot completed but no file URLs found.")
                    print(f"Snapshot complete. {len(file_urls)} file(s) available.")
                    print(f"ğŸ” file_urls ìƒì„¸: {file_urls}")
                    return {"type": "file_urls", "urls": file_urls}

                print("Still processing. Waiting 30 seconds...")
                time.sleep(30)
                wait_count += 30
                
            except requests.exceptions.Timeout:
                print("ìš”ì²­ íƒ€ì„ì•„ì›ƒ, 30ì´ˆ í›„ ì¬ì‹œë„...")
                time.sleep(30)
                wait_count += 30
                continue
                
            except Exception as e:
                print(f"Error while waiting for snapshot: {e}")
                time.sleep(30)
                wait_count += 30
        
        # íƒ€ì„ì•„ì›ƒ ì‹œì—ë„ ë¶€ë¶„ì ìœ¼ë¡œ ì™„ë£Œëœ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        try:
            print("â° ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼, ë§ˆì§€ë§‰ ìƒíƒœ í™•ì¸ ì¤‘...")
            response = requests.get(url, headers=headers, params=params, timeout=30)
            if response.status_code == 200:
                result = response.json()
                if result.get("status") == "done":
                    file_urls = result.get("file_urls", [])
                    if file_urls:
                        print(f"âœ… íƒ€ì„ì•„ì›ƒ í›„ì—ë„ ë°ì´í„° ë°œê²¬: {len(file_urls)}ê°œ íŒŒì¼")
                        return {"type": "file_urls", "urls": file_urls}
        except:
            pass
        
        raise Exception(f"Snapshot timeout after {max_wait_time} seconds")

    def download_snapshot_data(self, file_urls):
        """URL ë¦¬ìŠ¤íŠ¸ì—ì„œ JSON ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
        all_data = []
        
        # URL ìœ íš¨ì„± ê²€ì‚¬ ë° í•„í„°ë§
        valid_urls = []
        for url in file_urls:
            if isinstance(url, str) and url.startswith(('http://', 'https://')):
                valid_urls.append(url)
            else:
                print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ URL ê±´ë„ˆë›°ê¸°: {url} (íƒ€ì…: {type(url)})")
        
        if not valid_urls:
            print("âŒ ìœ íš¨í•œ URLì´ ì—†ìŠµë‹ˆë‹¤.")
            return all_data
        
        print(f"ğŸ“¥ {len(valid_urls)}ê°œì˜ ìœ íš¨í•œ URLì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘")
        
        for file_url in valid_urls:
            try:
                print(f"â¬‡ï¸ Downloading from: {file_url}")
                res = requests.get(file_url)
                res.raise_for_status()  # HTTP ì˜¤ë¥˜ ì²´í¬
                
                data = res.json()
                if isinstance(data, list):
                    all_data.extend(data)
                else:
                    all_data.append(data)
                    
            except requests.exceptions.RequestException as e:
                print(f"âŒ HTTP ìš”ì²­ ì‹¤íŒ¨ {file_url}: {e}")
            except ValueError as e:
                print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨ {file_url}: {e}")
            except Exception as e:
                print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ {file_url}: {e}")
        
        print(f"âœ… ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(all_data)}ê°œ í•­ëª©")
        return all_data

    async def get_reel_data(self, reel_url: str, config: dict) -> dict:
        """ì¸ìŠ¤íƒ€ê·¸ë¨ ë¦´ìŠ¤ URLì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. (ìº í˜ì¸ìš©)"""
        try:
            print(f"ğŸ¬ ë¦´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {reel_url}")
            
            # brightdata.jsonì—ì„œ ì„¤ì • ë¡œë“œ
            import json
            from pathlib import Path
            
            config_path = Path(__file__).parent / "backend" / "brightdata.json"
            with open(config_path, 'r', encoding='utf-8') as f:
                brightdata_config = json.load(f)
            
            # ë¦´ìŠ¤ ì„¤ì •ì—ì„œ params ê°€ì ¸ì˜¤ê¸°
            reel_config = brightdata_config.get("instagram", {}).get("reel", {})
            campaign_params = reel_config.get("params", {}).copy()
            
            # ìº í˜ì¸ìš©ìœ¼ë¡œ typeê³¼ discover_by ì œê±°
            campaign_params.pop("type", None)
            campaign_params.pop("discover_by", None)
            
            # configì—ì„œ include_errors ì„¤ì • ì ìš©
            if "include_errors" in config:
                campaign_params["include_errors"] = config["include_errors"]
            
            print(f"ìº í˜ì¸ ë¦´ìŠ¤ ì„¤ì •: {campaign_params}")
            
            # ë¦´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
            dataset_id = reel_config.get("dataset_id")
            if not dataset_id:
                raise ValueError("reel dataset_idê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ìŠ¤ëƒ…ìƒ· ìš”ì²­
            snapshot_id = self.trigger_snapshot_request(
                dataset_id=dataset_id,
                params=campaign_params,
                data={"url": reel_url}
            )
            
            # ìŠ¤ëƒ…ìƒ· ì™„ë£Œ ëŒ€ê¸°
            result = self.wait_for_snapshot(snapshot_id)
            
            # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            if result["type"] == "direct_data":
                reel_data = result["data"]
                print(f"ğŸ“Š ì§ì ‘ ë°˜í™˜ëœ ë¦´ìŠ¤ ë°ì´í„°: {len(reel_data)}ê°œ í•­ëª©")
                if reel_data and len(reel_data) > 0:
                    print(f"ğŸ“‹ ì²« ë²ˆì§¸ í•­ëª© í‚¤: {list(reel_data[0].keys()) if isinstance(reel_data[0], dict) else 'Not a dict'}")
            else: # result["type"] == "file_urls"
                file_urls = result["urls"]
                reel_data = self.download_snapshot_data(file_urls)
                print(f"ğŸ“Š íŒŒì¼ì—ì„œ ë‹¤ìš´ë¡œë“œëœ ë¦´ìŠ¤ ë°ì´í„°: {len(reel_data)}ê°œ í•­ëª©")
            
            print(f"âœ… ë¦´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {reel_url}")
            return reel_data
            
        except Exception as e:
            print(f"âŒ ë¦´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            raise

    async def get_post_data(self, post_url: str, config: dict) -> dict:
        """ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œë¬¼ URLì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. (ìº í˜ì¸ìš©)"""
        try:
            print(f"ğŸ“¸ ê²Œì‹œë¬¼ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {post_url}")
            
            # brightdata.jsonì—ì„œ ì„¤ì • ë¡œë“œ
            import json
            from pathlib import Path
            
            config_path = Path(__file__).parent / "backend" / "brightdata.json"
            with open(config_path, 'r', encoding='utf-8') as f:
                brightdata_config = json.load(f)
            
            # ê²Œì‹œë¬¼ ì„¤ì •ì—ì„œ params ê°€ì ¸ì˜¤ê¸°
            post_config = brightdata_config.get("instagram", {}).get("post", {})
            campaign_params = post_config.get("params", {}).copy()
            
            # ìº í˜ì¸ìš©ìœ¼ë¡œ typeê³¼ discover_by ì œê±°
            campaign_params.pop("type", None)
            campaign_params.pop("discover_by", None)
            
            # configì—ì„œ include_errors ì„¤ì • ì ìš©
            if "include_errors" in config:
                campaign_params["include_errors"] = config["include_errors"]
            
            print(f"ìº í˜ì¸ ê²Œì‹œë¬¼ ì„¤ì •: {campaign_params}")
            
            # ê²Œì‹œë¬¼ ë°ì´í„° ìˆ˜ì§‘
            dataset_id = post_config.get("dataset_id")
            if not dataset_id:
                raise ValueError("post dataset_idê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ìŠ¤ëƒ…ìƒ· ìš”ì²­
            snapshot_id = self.trigger_snapshot_request(
                dataset_id=dataset_id,
                params=campaign_params,
                data={"url": post_url}
            )
            
            # ìŠ¤ëƒ…ìƒ· ì™„ë£Œ ëŒ€ê¸°
            result = self.wait_for_snapshot(snapshot_id)
            
            # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            if result["type"] == "direct_data":
                post_data = result["data"]
                print(f"ğŸ“Š ì§ì ‘ ë°˜í™˜ëœ ê²Œì‹œë¬¼ ë°ì´í„°: {len(post_data)}ê°œ í•­ëª©")
                if post_data and len(post_data) > 0:
                    print(f"ğŸ“‹ ì²« ë²ˆì§¸ í•­ëª© í‚¤: {list(post_data[0].keys()) if isinstance(post_data[0], dict) else 'Not a dict'}")
            else: # result["type"] == "file_urls"
                file_urls = result["urls"]
                post_data = self.download_snapshot_data(file_urls)
                print(f"ğŸ“Š íŒŒì¼ì—ì„œ ë‹¤ìš´ë¡œë“œëœ ê²Œì‹œë¬¼ ë°ì´í„°: {len(post_data)}ê°œ í•­ëª©")
            
            print(f"âœ… ê²Œì‹œë¬¼ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {post_url}")
            return post_data
            
        except Exception as e:
            print(f"âŒ ê²Œì‹œë¬¼ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            raise