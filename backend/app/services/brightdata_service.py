import os
import json
import aiohttp
import asyncio
import logging
import sys
import csv
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
from .progress_service import progress_service
from .influencer_service import InfluencerService
from ..db.database import get_db

# instagram_api.py ì„í¬íŠ¸ (ë°±ì—”ë“œ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì— ë³µì‚¬ë¨)
backend_root = str(Path(__file__).parent.parent.parent)
if backend_root not in sys.path:
    sys.path.insert(0, backend_root)
from instagram_api import Instagram

logger = logging.getLogger(__name__)

KST_OFFSET = timedelta(hours=9)


def now_kst() -> datetime:
    return datetime.utcnow() + KST_OFFSET

class BrightDataService:
    def __init__(self, db_session=None):
        self.api_key = os.getenv("BRIGHTDATA_API_KEY")
        if not self.api_key:
            raise Exception("BRIGHTDATA_API_KEYê°€ í™˜ê²½ ë³€ìˆ˜ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # ì‹¤ì œ Instagram API í´ë˜ìŠ¤ ì‚¬ìš©
        self.instagram_api = Instagram()
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ ë° InfluencerService ì´ˆê¸°í™”
        self.db_session = db_session or next(get_db())
        self.influencer_service = InfluencerService(self.db_session)
        
        logger.info("BrightData Service initialized with real Instagram API")
        
        # ë°ì´í„° ìŠ¤ëƒ…ìƒ· ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.snapshot_dir = Path(__file__).parent.parent.parent / "data_snapshots"
        self.snapshot_dir.mkdir(exist_ok=True)
        
    async def collect_instagram_data_batch(self, urls: List[str], options: Dict[str, bool] = None, session_id: str = None) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ë¡œ ì¸ìŠ¤íƒ€ê·¸ë¨ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        logger.info(f"ğŸš€ BrightData ë°°ì¹˜ ìˆ˜ì§‘ ì‹œì‘: {len(urls)}ê°œ URL")
        
        # session_idë¥¼ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥ (í•˜ìœ„ ë©”ì„œë“œì—ì„œ ì‚¬ìš©)
        self._current_session_id = session_id
        
        results = []
        for i, url in enumerate(urls):
            try:
                logger.info(f"ğŸ“ [{i+1}/{len(urls)}] URL ìˆ˜ì§‘ ì‹œì‘: {url}")
                
                username = self._extract_username_from_url(url)
                logger.info(f"ğŸ¯ ì¶”ì¶œëœ ì‚¬ìš©ìëª…: {username}")
                
                if username == "unknown_user":
                    logger.warning(f"âš ï¸ ì‚¬ìš©ìëª… ì¶”ì¶œ ì‹¤íŒ¨: {url}")
                    results.append(self._create_empty_result(url))
                    continue
                
                # ì‹¤ì œ BrightData API ìŠ¤ëƒ…ìƒ· ë°©ì‹ ì‚¬ìš©
                try:
                    # URLì´ ê²Œì‹œë¬¼/ë¦´ìŠ¤ URLì¸ì§€ í”„ë¡œí•„ URLì¸ì§€ íŒë‹¨
                    if "/p/" in url or "/reel/" in url:
                        # ê²Œì‹œë¬¼ ë˜ëŠ” ë¦´ìŠ¤ URL
                        config = {"include_errors": True}
                        if "/reel/" in url:
                            data = await self.instagram_api.get_reel_data(url, config)
                        else:
                            data = await self.instagram_api.get_post_data(url, config)
                        
                        if data and len(data) > 0:
                            # ì²« ë²ˆì§¸ ë°ì´í„° í•­ëª©ì„ í”„ë¡œí•„ ì •ë³´ë¡œ ì‚¬ìš©
                            first_item = data[0] if isinstance(data, list) else data
                            result = {
                                "profile": {
                                    "username": first_item.get("user_posted", username),
                                    "full_name": first_item.get("user_posted", username),
                                    "followers": 0,
                                    "following": 0,
                                    "bio": "",
                                    "profile_pic_url": first_item.get("profile_url", ""),
                                    "account": "personal",
                                    "posts_count": 1
                                },
                                "posts": data if "/p/" in url else [],
                                "reels": data if "/reel/" in url else []
                            }
                        else:
                            result = self._create_empty_result(url)
                    else:
                        # í”„ë¡œí•„ URL - ì‹¤ì œ í”„ë¡œí•„ ìˆ˜ì§‘ êµ¬í˜„
                        logger.info(f"í”„ë¡œí•„ URL ìˆ˜ì§‘ ì‹œì‘: {url}")
                        
                        # ì‹¤ì œ BrightData API ì‚¬ìš©ìœ¼ë¡œ í”„ë¡œí•„ ìˆ˜ì§‘  
                        # session_idê°€ ìˆìœ¼ë©´ ì „ë‹¬
                        if hasattr(self, '_current_session_id'):
                            result = await self._collect_profile_with_brightdata(url, username, options, self._current_session_id)
                        else:
                            result = await self._collect_profile_with_brightdata(url, username, options)
                    
                    results.append(result)
                    logger.info(f"âœ… [{i+1}/{len(urls)}] URL ìˆ˜ì§‘ ì™„ë£Œ")
                    
                except Exception as api_error:
                    logger.error(f"ğŸ”¥ BrightData API í˜¸ì¶œ ì‹¤íŒ¨ {url}: {str(api_error)}")
                    # API ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì •ë³´ì™€ í•¨ê»˜ ê²°ê³¼ ë°˜í™˜
                    error_result = {
                        "profile": None,
                        "posts": [],
                        "reels": [],
                        "error": f"ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(api_error)}",
                        "status": "api_error",
                        "url": url
                    }
                    results.append(error_result)
                
            except Exception as e:
                logger.error(f"âŒ [{i+1}/{len(urls)}] URL ìˆ˜ì§‘ ì‹¤íŒ¨ {url}: {str(e)}")
                error_result = {
                    "profile": None,
                    "posts": [],
                    "reels": [],
                    "error": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                    "status": "processing_error",
                    "url": url
                }
                results.append(error_result)
        
        logger.info(f"ğŸ‰ ë°°ì¹˜ ìˆ˜ì§‘ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
        return results
    
    async def _collect_single_data_type(self, url: str, username: str, data_type: str, max_retries: int = 2) -> Dict[str, Any]:
        """ë‹¨ì¼ ë°ì´í„° íƒ€ì…(profile ë˜ëŠ” reels)ì„ ê°œë³„ì ìœ¼ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤. ì¬ì‹œë„ ë¡œì§ í¬í•¨."""
        logger.info(f"ğŸŒ BrightData API {data_type} ìˆ˜ì§‘: {username} ({url})")
        
        for attempt in range(max_retries + 1):
            try:
                if attempt > 0:
                    logger.info(f"ğŸ”„ {data_type} ìˆ˜ì§‘ ì¬ì‹œë„ {attempt}/{max_retries}: {username}")
                    # ì¬ì‹œë„ ì‹œ ì ì‹œ ëŒ€ê¸°
                    await asyncio.sleep(5)
                
                # brightdata.jsonì—ì„œ ì„¤ì • ë¡œë“œ
                import json
                from pathlib import Path
                
                config_path = Path(__file__).parent.parent.parent / "brightdata.json"
                try:
                    with open(config_path, 'r', encoding='utf-8') as f:
                        brightdata_config = json.load(f)
                except (FileNotFoundError, json.JSONDecodeError) as e:
                    logger.error(f"âŒ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                    if attempt == max_retries:
                        return {}
                    continue
                
                instagram_config = brightdata_config.get("instagram", {})
                
                if data_type == "profile":
                    config = instagram_config.get("profile", {})
                    input_data = [{
                        "user_name": username
                    }]
                elif data_type == "reels":
                    config = instagram_config.get("reel", {})
                    input_data = [{
                        "url": url,
                        "num_of_posts": 24,
                        "start_date": "",
                        "end_date": now_kst().strftime("%m-%d-%Y")
                    }]
                else:
                    logger.error(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° íƒ€ì…: {data_type}")
                    return {}
                
                dataset_id = config.get("dataset_id")
                params = config.get("params", {})
                
                if not dataset_id:
                    logger.error(f"{data_type} ë°ì´í„°ì…‹ IDê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                    return {}
                
                # ìŠ¤ëƒ…ìƒ· ìš”ì²­ (ì¬ì‹œë„ ì‹œ ë” ê°•ë ¥í•œ ì˜¤ë¥˜ ì²˜ë¦¬)
                try:
                    snapshot_id = self.instagram_api.trigger_snapshot_request(
                        dataset_id=dataset_id,
                        params=params,
                        data=input_data
                    )
                except Exception as snapshot_error:
                    logger.error(f"âŒ ìŠ¤ëƒ…ìƒ· ìš”ì²­ ì‹¤íŒ¨ ({attempt+1}/{max_retries+1}): {str(snapshot_error)}")
                    if attempt == max_retries:
                        return {}
                    continue
                
                if not snapshot_id:
                    logger.error(f"âŒ {data_type} ìŠ¤ëƒ…ìƒ· IDë¥¼ ë°›ì§€ ëª»í•¨ ({attempt+1}/{max_retries+1})")
                    if attempt == max_retries:
                        return {}
                    continue
                    
                logger.info(f"âœ… {data_type} ìŠ¤ëƒ…ìƒ· ID: {snapshot_id}")
                
                # ìŠ¤ëƒ…ìƒ· ì™„ë£Œ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬)
                try:
                    raw_data = self.instagram_api.wait_for_snapshot(snapshot_id, data_type)
                except Exception as wait_error:
                    logger.error(f"âŒ ìŠ¤ëƒ…ìƒ· ëŒ€ê¸° ì‹¤íŒ¨ ({attempt+1}/{max_retries+1}): {str(wait_error)}")
                    if attempt == max_retries:
                        return {}
                    continue
                
                if not raw_data:
                    logger.error(f"âŒ {data_type} ìŠ¤ëƒ…ìƒ· ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ ({attempt+1}/{max_retries+1})")
                    if attempt == max_retries:
                        # ë§ˆì§€ë§‰ ì¬ì‹œë„ì—ì„œë„ ì‹¤íŒ¨í•˜ë©´ ê¸°ë³¸ ë°ì´í„° ë°˜í™˜
                        if data_type == "profile":
                            profile_data = self._create_default_profile(username)
                            return {"profile": profile_data}
                        return {}
                    continue
                
                # ì›ì‹œ ë°ì´í„° ìƒíƒœ ë¡œê¹…
                logger.info(f"ğŸ” {data_type} ì›ì‹œ ë°ì´í„° íƒ€ì…: {type(raw_data)}")
                
                # raw_dataê°€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
                if isinstance(raw_data, list):
                    logger.info(f"ğŸ” {data_type} ì›ì‹œ ë°ì´í„° ë¶„ì„: ì´ {len(raw_data)}ê°œ í•­ëª©")
                    # ì²˜ìŒ 3ê°œë§Œ ë¡œê¹… (ì•ˆì „í•˜ê²Œ)
                    for i in range(min(3, len(raw_data))):
                        item = raw_data[i]
                        logger.info(f"  [{i}] íƒ€ì…: {type(item)}, ë‚´ìš©: {str(item)[:200]}")
                    
                    # ìœ íš¨í•œ ë”•ì…”ë„ˆë¦¬ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                    valid_items = [item for item in raw_data if isinstance(item, dict)]
                    logger.info(f"ğŸ“Š ìœ íš¨í•œ ë”•ì…”ë„ˆë¦¬ ë°ì´í„°: {len(valid_items)}/{len(raw_data)}ê°œ")
                else:
                    logger.info(f"ğŸ” {data_type} ì›ì‹œ ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹˜: {str(raw_data)[:200]}")
                    # raw_dataê°€ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    if isinstance(raw_data, dict):
                        raw_data = [raw_data]
                        logger.info(f"ğŸ”„ ë”•ì…”ë„ˆë¦¬ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜: {len(raw_data)}ê°œ í•­ëª©")
                    else:
                        logger.error(f"âŒ ì˜ˆìƒí•˜ì§€ ëª»í•œ ë°ì´í„° íƒ€ì…: {type(raw_data)}")
                        if attempt == max_retries:
                            return {}
                        continue
                
                # ë°ì´í„° íŒŒì‹±
                if data_type == "profile":
                    logger.info(f"í”„ë¡œí•„ íŒŒì‹± ì‹œì‘: {username}, {len(raw_data) if hasattr(raw_data, '__len__') else 'N/A'}ê°œ í•­ëª©")
                    
                    # ì›ë³¸ ë°ì´í„° ì €ì¥ (íŒŒì‹± ì „)
                    try:
                        json_path, csv_path = self._save_snapshot_data(raw_data, username, f"{data_type}_single")
                        logger.info(f"ğŸ“ ì›ë³¸ single {data_type} ë°ì´í„° ì €ì¥: JSON={json_path}, CSV={csv_path}")
                    except Exception as save_error:
                        logger.error(f"âŒ ì›ë³¸ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(save_error)}")
                    
                    profile_data = None
                    for i, item in enumerate(raw_data):
                        logger.debug(f"í”„ë¡œí•„ ì•„ì´í…œ [{i}] íƒ€ì…: {type(item)}")
                        
                        # íƒ€ì… ê²€ì¦ ì¶”ê°€
                        if not isinstance(item, dict):
                            logger.warning(f"âš ï¸ í”„ë¡œí•„ ë°ì´í„° íƒ€ì… ìŠ¤í‚µ: {type(item)} - {str(item)[:100]}")
                            continue
                        profile_data = self._extract_profile_from_item(item, username)
                        if profile_data:
                            logger.info(f"âœ… í”„ë¡œí•„ ë°ì´í„° ì¶”ì¶œ ì„±ê³µ: {profile_data['username']}")
                            break
                    
                    # í”„ë¡œí•„ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¡œí•„ ìƒì„±
                    if not profile_data:
                        logger.warning(f"âš ï¸ {username} í”„ë¡œí•„ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨ - ê¸°ë³¸ í”„ë¡œí•„ ìƒì„±")
                        profile_data = self._create_default_profile(username)
                    
                    # ì¶”ì¶œëœ í”„ë¡œí•„ ë°ì´í„° ì €ì¥
                    if profile_data:
                        try:
                            extracted_json_path, extracted_csv_path = self._save_snapshot_data([profile_data], username, f"{data_type}_single_extracted")
                            logger.info(f"ğŸ“ ì¶”ì¶œëœ single {data_type} ë°ì´í„° ì €ì¥: JSON={extracted_json_path}, CSV={extracted_csv_path}")
                        except Exception as save_error:
                            logger.error(f"âŒ ì¶”ì¶œëœ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(save_error)}")
                    
                    # ë°ì´í„°ë² ì´ìŠ¤ì— í”„ë¡œí•„ ì €ì¥
                    try:
                        saved_profile = self.influencer_service.create_or_update_profile(profile_data, username)
                        logger.info(f"ğŸ’¾ í”„ë¡œí•„ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ: {saved_profile.username} (ID: {saved_profile.id})")
                    except Exception as db_error:
                        logger.error(f"âŒ í”„ë¡œí•„ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {str(db_error)}")
                    
                    logger.info(f"âœ… {data_type} ìˆ˜ì§‘ ì„±ê³µ: {username}")
                    return {"profile": profile_data}
                
                elif data_type == "reels":
                    # ì›ë³¸ ë°ì´í„° ì €ì¥ (íŒŒì‹± ì „)
                    try:
                        json_path, csv_path = self._save_snapshot_data(raw_data, username, f"{data_type}_single")
                        logger.info(f"ğŸ“ ì›ë³¸ single {data_type} ë°ì´í„° ì €ì¥: JSON={json_path}, CSV={csv_path}")
                    except Exception as save_error:
                        logger.error(f"âŒ ì›ë³¸ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(save_error)}")
                    
                    reels_data = []
                    processed_items = 0
                    
                    # BrightData ë˜í•‘ëœ ë°ì´í„° êµ¬ì¡° ì²˜ë¦¬
                    actual_data = []
                    for item in raw_data:
                        if isinstance(item, dict) and item.get('type') == 'direct_data' and 'data' in item:
                            # ë˜í•‘ëœ ë°ì´í„° ì–¸ë˜í•‘
                            actual_data.extend(item['data'])
                        elif isinstance(item, dict):
                            # ì§ì ‘ ë°ì´í„°
                            actual_data.append(item)
                    
                    logger.info(f"ğŸ“Š {data_type} ë°ì´í„° ì–¸ë˜í•‘: {len(raw_data)}ê°œ â†’ {len(actual_data)}ê°œ")
                    
                    # ì–¸ë˜í•‘ëœ ë°ì´í„°ë„ ì €ì¥
                    if actual_data:
                        try:
                            unwrapped_json_path, unwrapped_csv_path = self._save_snapshot_data(actual_data, username, f"{data_type}_single_unwrapped")
                            logger.info(f"ğŸ“ ì–¸ë˜í•‘ëœ single {data_type} ë°ì´í„° ì €ì¥: JSON={unwrapped_json_path}, CSV={unwrapped_csv_path}")
                        except Exception as save_error:
                            logger.error(f"âŒ ì–¸ë˜í•‘ëœ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(save_error)}")
                    
                    for item in actual_data:
                        # íƒ€ì… ê²€ì¦ ì¶”ê°€
                        if not isinstance(item, dict):
                            logger.warning(f"âš ï¸ ë¦´ìŠ¤ ë°ì´í„° íƒ€ì… ìŠ¤í‚µ: {type(item)} - {str(item)[:100]}")
                            continue
                        
                        processed_items += 1
                        try:
                            if self._is_reel_item(item):
                                reel = self._extract_reel_from_item(item, username)
                                if reel:
                                    reels_data.append(reel)
                                    logger.info(f"âœ… ë¦´ìŠ¤ íŒŒì‹± ì„±ê³µ: {reel['reel_id']} | ì¡°íšŒìˆ˜: {reel['views']}")
                        except Exception as item_error:
                            logger.warning(f"âš ï¸ ë¦´ìŠ¤ ì•„ì´í…œ ì²˜ë¦¬ ì˜¤ë¥˜: {str(item_error)}")
                            continue
                    
                    logger.info(f"ğŸ“Š {data_type} ì²˜ë¦¬ ì™„ë£Œ: ì²˜ë¦¬ëœ ì•„ì´í…œ {processed_items}ê°œ, ë¦´ìŠ¤ {len(reels_data)}ê°œ")
                    
                    # ì¶”ì¶œëœ ë¦´ìŠ¤ ë°ì´í„° ì €ì¥
                    if reels_data:
                        try:
                            extracted_json_path, extracted_csv_path = self._save_snapshot_data(reels_data, username, f"{data_type}_single_extracted")
                            logger.info(f"ğŸ“ ì¶”ì¶œëœ single {data_type} ë°ì´í„° ì €ì¥: JSON={extracted_json_path}, CSV={extracted_csv_path}")
                        except Exception as save_error:
                            logger.error(f"âŒ ì¶”ì¶œëœ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(save_error)}")
                    
                    # ì ˆëŒ€ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŒ (ëª…ì‹œì  ê¸ˆì§€)
                    if not reels_data:
                        logger.warning(f"âš ï¸ {username} ì‹¤ì œ ë¦´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŒ - ì›ì‹œ ë°ì´í„° ë¶„ì„")
                        logger.warning(f"ğŸ” ì›ì‹œ ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ): {raw_data[:3] if raw_data else 'ì—†ìŒ'}")
                        
                        # ì›ì‹œ ë°ì´í„° êµ¬ì¡° ë¶„ì„
                        if raw_data:
                            for i, item in enumerate(raw_data[:5]):
                                logger.warning(f"   [{i}] íƒ€ì…: {type(item)}, í‚¤: {list(item.keys()) if isinstance(item, dict) else 'N/A'}")
                                if isinstance(item, dict):
                                    logger.warning(f"       _is_reel_item: {self._is_reel_item(item)}")
                        reels_data = []
                    
                    logger.info(f"âœ… {data_type} ìˆ˜ì§‘ ì„±ê³µ: {username} - {len(reels_data)}ê°œ ë¦´ìŠ¤")
                    return {"reels": reels_data}
                
            except asyncio.TimeoutError:
                logger.error(f"â° {data_type} ìˆ˜ì§‘ íƒ€ì„ì•„ì›ƒ ({attempt+1}/{max_retries+1}): {username}")
                if attempt == max_retries:
                    # íƒ€ì„ì•„ì›ƒì´ì§€ë§Œ ê¸°ë³¸ ë°ì´í„°ë¼ë„ ë°˜í™˜
                    if data_type == "profile":
                        profile_data = self._create_default_profile(username)
                        return {"profile": profile_data}
                    return {}
                continue
                
            except Exception as e:
                import traceback
                logger.error(f"âŒ {data_type} ìˆ˜ì§‘ ì‹¤íŒ¨ ({attempt+1}/{max_retries+1}): {str(e)}")
                logger.error(f"âŒ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
                if attempt == max_retries:
                    # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë°ì´í„° ë°˜í™˜
                    if data_type == "profile":
                        profile_data = self._create_default_profile(username)
                        return {"profile": profile_data}
                    return {}
                continue
        
        # ì´ ì§€ì ì— ë„ë‹¬í•˜ë©´ ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
        logger.error(f"ğŸ’¥ {data_type} ìˆ˜ì§‘ ì™„ì „ ì‹¤íŒ¨: {username}")
        if data_type == "profile":
            profile_data = self._create_default_profile(username)
            return {"profile": profile_data}
        return {}

    async def _collect_profile_with_brightdata(self, url: str, username: str, options: Dict[str, bool] = None, session_id: str = None) -> Dict[str, Any]:
        """ì‹¤ì œ BrightData APIë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡œí•„, ê²Œì‹œë¬¼, ë¦´ìŠ¤ë¥¼ ëª¨ë‘ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        logger.info(f"ğŸŒ BrightData API í”„ë¡œí•„ + ê²Œì‹œë¬¼ + ë¦´ìŠ¤ ìˆ˜ì§‘: {username} ({url})")
        
        try:
            # brightdata.jsonì—ì„œ ì„¤ì • ë¡œë“œ
            import json
            from pathlib import Path
            
            config_path = Path(__file__).parent.parent.parent / "brightdata.json"
            with open(config_path, 'r', encoding='utf-8') as f:
                brightdata_config = json.load(f)
            
            instagram_config = brightdata_config.get("instagram", {})
            
            # ìˆ˜ì§‘í•  ë°ì´í„° ìœ í˜•ë“¤
            collection_tasks = []
            
            # 1. í”„ë¡œí•„ ë°ì´í„° ìˆ˜ì§‘
            if options is None or options.get("collectProfile", True):
                profile_config = instagram_config.get("profile", {})
                if profile_config.get("dataset_id"):
                    profile_data = [{"url": url}]
                    collection_tasks.append(("profile", profile_config, profile_data))
            
            # ê²Œì‹œë¬¼ ìˆ˜ì§‘ ë¹„í™œì„±í™”ë¨
            
            # 3. ë¦´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ (í”„ë¡œí•„ URLì„ ì‚¬ìš©í•˜ì—¬ ìµœì‹  ë¦´ìŠ¤ë“¤ ìˆ˜ì§‘)  
            if options is None or options.get("collectReels", True):
                reel_config = instagram_config.get("reel", {})
                if reel_config.get("dataset_id"):
                    # BrightData API ìš”êµ¬ í˜•ì‹ì— ë§ì¶° ë¦´ìŠ¤ ìˆ˜ì§‘ íŒŒë¼ë¯¸í„° êµ¬ì„±
                    reels_data = [{
                        "url": url,
                        "num_of_posts": 24,
                        "start_date": "",
                        "end_date": now_kst().strftime("%m-%d-%Y")
                    }]
                    collection_tasks.append(("reels", reel_config, reels_data))
            
            if not collection_tasks:
                logger.warning("ìˆ˜ì§‘í•  ë°ì´í„° ìœ í˜•ì´ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
                return self._create_empty_result_with_error(url, "ìˆ˜ì§‘ ì„¤ì •ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ")
            
            # ê° ë°ì´í„° ìœ í˜•ë³„ë¡œ ìˆ˜ì§‘ ì‹¤í–‰
            collected_data = {"profile": None, "posts": [], "reels": []}
            
            for data_type, config, input_params in collection_tasks:
                try:
                    logger.info(f"ğŸ“¡ {data_type.upper()} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
                    
                    # ì„¸ë¶€ ì§„í–‰ë¥  ì´ˆê¸°í™”
                    current_session_id = getattr(self, '_current_session_id', None)
                    if current_session_id:
                        await progress_service.send_detail_progress(
                            current_session_id, 
                            data_type, 
                            "running", 
                            0, 
                            1, 
                            f"{data_type.title()} ë°ì´í„° ìˆ˜ì§‘ ìš”ì²­ ì‹œì‘"
                        )
                    
                    dataset_id = config.get("dataset_id")
                    params = config.get("params", {})
                    
                    # ìŠ¤ëƒ…ìƒ· ìš”ì²­
                    snapshot_id = self.instagram_api.trigger_snapshot_request(
                        dataset_id=dataset_id,
                        params=params,
                        data=input_params
                    )
                    
                    if not snapshot_id:
                        logger.error(f"{data_type} ìŠ¤ëƒ…ìƒ· IDë¥¼ ë°›ì§€ ëª»í•¨")
                        continue
                        
                    logger.info(f"âœ… {data_type} ìŠ¤ëƒ…ìƒ· ID: {snapshot_id}")
                    
                    # ìŠ¤ëƒ…ìƒ· ì™„ë£Œ ëŒ€ê¸° (ë°ì´í„° íƒ€ì…ê³¼ ì„¸ì…˜ ID ì „ë‹¬)
                    current_session_id = getattr(self, '_current_session_id', None)
                    snapshot_result = self.instagram_api.wait_for_snapshot(snapshot_id, data_type, current_session_id)
                    
                    if not snapshot_result:
                        logger.error(f"{data_type} ìŠ¤ëƒ…ìƒ· ë°ì´í„°ë¥¼ ë°›ì§€ ëª»í•¨")
                        continue
                    
                    # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
                    if snapshot_result["type"] == "direct_data":
                        data = snapshot_result["data"]
                        logger.info(f"ğŸ“Š {data_type} ì§ì ‘ ë°ì´í„° ìˆ˜ì‹ : {len(data)}ê°œ í•­ëª©")
                    elif snapshot_result["type"] == "file_urls":
                        data = self.instagram_api.download_snapshot_data(snapshot_result["urls"])
                        logger.info(f"ğŸ“¥ {data_type} íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(data)}ê°œ í•­ëª©")
                    else:
                        logger.error(f"{data_type} ì•Œ ìˆ˜ ì—†ëŠ” ìŠ¤ëƒ…ìƒ· ê²°ê³¼ íƒ€ì…")
                        continue
                    
                    if data and len(data) > 0:
                        # ë°ì´í„° ìœ í˜•ë³„ ì²˜ë¦¬
                        if data_type == "profile":
                            # ì›ë³¸ ë°ì´í„° ì €ì¥ (ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì „)
                            try:
                                json_path, csv_path = self._save_snapshot_data(data, username, data_type)
                                logger.info(f"ğŸ“ ì›ë³¸ {data_type} ë°ì´í„° ì €ì¥: JSON={json_path}, CSV={csv_path}")
                            except Exception as save_error:
                                logger.error(f"âŒ ì›ë³¸ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(save_error)}")
                            
                            profile_data = self._extract_profile_from_brightdata(data, username)
                            if profile_data:
                                collected_data["profile"] = profile_data
                                logger.info(f"âœ… í”„ë¡œí•„ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ")
                                
                                # ì¶”ì¶œëœ í”„ë¡œí•„ ë°ì´í„°ë„ ë³„ë„ ì €ì¥
                                try:
                                    extracted_json_path, extracted_csv_path = self._save_snapshot_data([profile_data], username, f"{data_type}_extracted")
                                    logger.info(f"ğŸ“ ì¶”ì¶œëœ {data_type} ë°ì´í„° ì €ì¥: JSON={extracted_json_path}, CSV={extracted_csv_path}")
                                except Exception as save_error:
                                    logger.error(f"âŒ ì¶”ì¶œëœ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(save_error)}")
                                
                                # ë°ì´í„°ë² ì´ìŠ¤ì— í”„ë¡œí•„ ì €ì¥
                                try:
                                    saved_profile = self.influencer_service.create_or_update_profile(profile_data, username)
                                    logger.info(f"ğŸ’¾ í”„ë¡œí•„ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ: {saved_profile.username} (ID: {saved_profile.id})")
                                except Exception as db_error:
                                    logger.error(f"âŒ í”„ë¡œí•„ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {str(db_error)}")
                                
                                # ì„¸ë¶€ ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
                                if current_session_id:
                                    await progress_service.send_detail_progress(
                                        current_session_id, "profile", "completed", 1, 1, "í”„ë¡œí•„ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ"
                                    )
                        
                        elif data_type == "posts":
                            posts_data = self._extract_posts_from_brightdata(data, username)
                            collected_data["posts"].extend(posts_data)
                            logger.info(f"âœ… ê²Œì‹œë¬¼ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {len(posts_data)}ê°œ")
                            # ì„¸ë¶€ ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
                            if current_session_id:
                                await progress_service.send_detail_progress(
                                    current_session_id, "posts", "completed", 1, 1, f"ê²Œì‹œë¬¼ {len(posts_data)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ"
                                )
                        
                        elif data_type == "reels":
                            # ì›ë³¸ ë°ì´í„° ì €ì¥ (ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì „)
                            try:
                                json_path, csv_path = self._save_snapshot_data(data, username, data_type)
                                logger.info(f"ğŸ“ ì›ë³¸ {data_type} ë°ì´í„° ì €ì¥: JSON={json_path}, CSV={csv_path}")
                            except Exception as save_error:
                                logger.error(f"âŒ ì›ë³¸ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(save_error)}")
                            
                            reels_data = self._extract_reels_from_brightdata(data, username)
                            collected_data["reels"].extend(reels_data)
                            logger.info(f"âœ… ë¦´ìŠ¤ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ: {len(reels_data)}ê°œ")
                            
                            # ì¶”ì¶œëœ ë¦´ìŠ¤ ë°ì´í„°ë„ ë³„ë„ ì €ì¥
                            if reels_data:
                                try:
                                    extracted_json_path, extracted_csv_path = self._save_snapshot_data(reels_data, username, f"{data_type}_extracted")
                                    logger.info(f"ğŸ“ ì¶”ì¶œëœ {data_type} ë°ì´í„° ì €ì¥: JSON={extracted_json_path}, CSV={extracted_csv_path}")
                                except Exception as save_error:
                                    logger.error(f"âŒ ì¶”ì¶œëœ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(save_error)}")
                            
                            # ì„¸ë¶€ ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸
                            if current_session_id:
                                await progress_service.send_detail_progress(
                                    current_session_id, "reels", "completed", 1, 1, f"ë¦´ìŠ¤ {len(reels_data)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ"
                                )
                    else:
                        logger.warning(f"âš ï¸ {data_type} ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ")
                        # ì„¸ë¶€ ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸ (ì‹¤íŒ¨)
                        if current_session_id:
                            await progress_service.send_detail_progress(
                                current_session_id, data_type, "completed", 1, 1, f"{data_type.title()} ë°ì´í„° ì—†ìŒ"
                            )
                    
                except Exception as e:
                    logger.error(f"ğŸ”¥ {data_type} ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
                    # ì„¸ë¶€ ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸ (ì‹¤íŒ¨)
                    if current_session_id:
                        await progress_service.send_detail_progress(
                            current_session_id, data_type, "failed", 0, 1, f"{data_type.title()} ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}"
                        )
                    continue
            
            # ê¸°ë³¸ í”„ë¡œí•„ì´ ì—†ìœ¼ë©´ ìƒì„±
            if not collected_data["profile"]:
                collected_data["profile"] = self._create_default_profile(username)
                # ê¸°ë³¸ í”„ë¡œí•„ë„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                try:
                    saved_profile = self.influencer_service.create_or_update_profile(collected_data["profile"], username)
                    logger.info(f"ğŸ’¾ ê¸°ë³¸ í”„ë¡œí•„ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ: {saved_profile.username} (ID: {saved_profile.id})")
                except Exception as db_error:
                    logger.error(f"âŒ ê¸°ë³¸ í”„ë¡œí•„ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {str(db_error)}")
            
            # ì ˆëŒ€ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŒ (ëª…ì‹œì  ê¸ˆì§€)
            if len(collected_data["reels"]) == 0:
                logger.info(f"âš ï¸ ì‹¤ì œ ë¦´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŒ - í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±í•˜ì§€ ì•ŠìŒ")
                collected_data["reels"] = []
            
            logger.info(f"ğŸ‰ í†µí•© ìˆ˜ì§‘ ì™„ë£Œ: í”„ë¡œí•„={1 if collected_data['profile'] else 0}, ë¦´ìŠ¤={len(collected_data['reels'])}")
            return collected_data
            
        except Exception as e:
            logger.error(f"ğŸ”¥ BrightData API í†µí•© ìˆ˜ì§‘ ì‹¤íŒ¨ {username}: {str(e)}")
            return self._create_empty_result_with_error(url, f"BrightData API ì˜¤ë¥˜: {str(e)}")
    
    def _process_brightdata_response(self, raw_data: List[Dict], username: str, options: Dict[str, bool] = None) -> Dict[str, Any]:
        """BrightData ì›ì‹œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì—¬ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        logger.info(f"ğŸ”„ BrightData ë°ì´í„° ì²˜ë¦¬ ì‹œì‘: {len(raw_data)}ê°œ í•­ëª©")
        
        if not options:
            options = {"collectProfile": True, "collectPosts": True, "collectReels": True}
        
        profile_data = None
        posts_data = []
        reels_data = []
        
        # BrightData Instagram ë°ì´í„° íŒŒì‹±
        for idx, item in enumerate(raw_data):
            try:
                # ë°ì´í„° íƒ€ì… ê²€ì¦ - ë¬¸ìì—´ì¸ ê²½ìš° ìŠ¤í‚µ
                if not isinstance(item, dict):
                    logger.warning(f"âš ï¸ [{idx+1}/{len(raw_data)}] ì˜ëª»ëœ ë°ì´í„° íƒ€ì… ìŠ¤í‚µ: {type(item)} - {str(item)[:100]}")
                    continue
                
                logger.info(f"ğŸ” [{idx+1}/{len(raw_data)}] ì•„ì´í…œ ì²˜ë¦¬: {list(item.keys())}")
                
                # í”„ë¡œí•„ ì •ë³´ ì¶”ì¶œ (ë³´í†µ ì²« ë²ˆì§¸ ì•„ì´í…œì— ìˆìŒ)
                if not profile_data and options.get("collectProfile", True):
                    profile_data = self._extract_profile_from_item(item, username)
                    if profile_data:
                        # ë°ì´í„°ë² ì´ìŠ¤ì— í”„ë¡œí•„ ì €ì¥
                        try:
                            saved_profile = self.influencer_service.create_or_update_profile(profile_data, username)
                            logger.info(f"ğŸ’¾ í”„ë¡œí•„ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ: {saved_profile.username} (ID: {saved_profile.id})")
                        except Exception as db_error:
                            logger.error(f"âŒ í”„ë¡œí•„ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {str(db_error)}")
                
                # ê²Œì‹œë¬¼/ë¦´ìŠ¤ ë°ì´í„° ì¶”ì¶œ
                if self._is_post_item(item):
                    if options.get("collectPosts", True):
                        post = self._extract_post_from_item(item, username)
                        if post:
                            posts_data.append(post)
                elif self._is_reel_item(item):
                    if options.get("collectReels", True):
                        reel = self._extract_reel_from_item(item, username)
                        if reel:
                            reels_data.append(reel)
                
            except Exception as e:
                logger.warning(f"âš ï¸ ì•„ì´í…œ ì²˜ë¦¬ ì˜¤ë¥˜ [{idx}]: {str(e)}")
                continue
        
        # ê¸°ë³¸ í”„ë¡œí•„ ìƒì„± (ë°ì´í„°ê°€ ì—†ìœ¼ë©´)
        if not profile_data and options.get("collectProfile", True):
            profile_data = self._create_default_profile(username)
            # ê¸°ë³¸ í”„ë¡œí•„ë„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            try:
                saved_profile = self.influencer_service.create_or_update_profile(profile_data, username)
                logger.info(f"ğŸ’¾ ê¸°ë³¸ í”„ë¡œí•„ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ: {saved_profile.username} (ID: {saved_profile.id})")
            except Exception as db_error:
                logger.error(f"âŒ ê¸°ë³¸ í”„ë¡œí•„ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {str(db_error)}")
        
        result = {
            "profile": profile_data,
            "posts": posts_data,
            "reels": reels_data
        }
        
        logger.info(f"âœ… BrightData ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: í”„ë¡œí•„={1 if profile_data else 0}, ê²Œì‹œë¬¼={len(posts_data)}, ë¦´ìŠ¤={len(reels_data)}")
        return result
    
    def _extract_profile_from_item(self, item: Dict, username: str) -> Optional[Dict]:
        """ì•„ì´í…œì—ì„œ í”„ë¡œí•„ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        try:
            logger.debug(f"í”„ë¡œí•„ ì¶”ì¶œ ì‹œì‘: {username}")
            
            # ë°ì´í„° íƒ€ì… ê²€ì¦
            if not isinstance(item, dict):
                logger.warning(f"âš ï¸ í”„ë¡œí•„ ì¶”ì¶œ ìŠ¤í‚µ: ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ë°ì´í„° íƒ€ì… {type(item)}")
                return None
            
            logger.debug(f"BrightData ì›ì‹œ ë°ì´í„° í‚¤ë“¤: {list(item.keys())}")
            
            # ğŸ”§ BrightData ì¤‘ì²© êµ¬ì¡° ì²˜ë¦¬ (type: "direct_data", data: [...])
            actual_item = item
            if item.get("type") == "direct_data" and "data" in item:
                data_list = item["data"]
                if isinstance(data_list, list) and len(data_list) > 0:
                    actual_item = data_list[0]  # ì²« ë²ˆì§¸ ë°ì´í„° í•­ëª© ì‚¬ìš©
                    logger.debug(f"ì¤‘ì²© êµ¬ì¡° ê°ì§€: direct_data -> ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ")
                else:
                    logger.warning(f"direct_data êµ¬ì¡°ì´ì§€ë§Œ dataê°€ ë¹„ì–´ìˆìŒ")
                    return None
                
            # ğŸ”§ BrightData ì‹¤ì œ ì‘ë‹µ êµ¬ì¡°ì— ë§ì¶˜ ì˜¬ë°”ë¥¸ í•„ë“œ ë§¤í•‘
            extracted_username = actual_item.get("account") or actual_item.get("user_posted") or actual_item.get("username") or actual_item.get("user_name") or username
            extracted_full_name = actual_item.get("full_name") or actual_item.get("profile_name") or actual_item.get("name") or actual_item.get("display_name") or extracted_username
            
            profile = {
                "username": extracted_username,
                "full_name": extracted_full_name,
                "followers": self._safe_int(actual_item.get("followers") or actual_item.get("follower_count") or actual_item.get("followers_count") or actual_item.get("followers_total") or actual_item.get("subscriber_count")),
                "following": self._safe_int(actual_item.get("following") or actual_item.get("following_count") or actual_item.get("follows_count") or actual_item.get("followings")),
                "bio": actual_item.get("biography") or actual_item.get("bio") or actual_item.get("description") or "",
                "profile_pic_url": actual_item.get("profile_image_link") or actual_item.get("profile_pic_url") or actual_item.get("avatar_url") or actual_item.get("profile_picture") or "",
                "account": "business" if actual_item.get("is_business_account") or actual_item.get("business_account") else "personal",
                "posts_count": self._safe_int(actual_item.get("posts_count") or actual_item.get("media_count") or actual_item.get("post_count")),
                "avg_engagement": self._safe_float(actual_item.get("avg_engagement") or actual_item.get("engagement_rate") or 0),
                "category_name": actual_item.get("category_name") or actual_item.get("business_category_name") or actual_item.get("category") or "",
                "profile_name": extracted_full_name,
                "email_address": actual_item.get("email_address") or actual_item.get("email"),
                "is_business_account": bool(actual_item.get("is_business_account") or actual_item.get("business_account")),
                "is_professional_account": bool(actual_item.get("is_professional_account") or actual_item.get("professional_account")),
                "is_verified": bool(actual_item.get("is_verified") or actual_item.get("verified"))
            }
            
            # ìœ íš¨í•œ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸ - BrightData ì‘ë‹µì— ë§ì¶˜ ê²€ì¦
            # extracted_usernameì´ë‚˜ extracted_full_name ì¤‘ í•˜ë‚˜ë¼ë„ ì‹¤ì œ ê°’ì´ ìˆìœ¼ë©´ ìœ íš¨
            if (extracted_username and extracted_username != username) or (extracted_full_name and extracted_full_name != extracted_username):
                logger.info(f"ğŸ‘¤ í”„ë¡œí•„ ì¶”ì¶œ ì„±ê³µ: {profile['username']} (íŒ”ë¡œì›Œ: {profile['followers']}) - {profile['full_name']}")
                return profile
            elif extracted_username == username and profile["followers"] > 0:
                # usernameì€ ê°™ì§€ë§Œ íŒ”ë¡œì›Œ ìˆ˜ê°€ ìˆìœ¼ë©´ ìœ íš¨í•œ í”„ë¡œí•„
                logger.info(f"ğŸ‘¤ í”„ë¡œí•„ ì¶”ì¶œ ì„±ê³µ (íŒ”ë¡œì›Œ ê¸°ë°˜): {profile['username']} (íŒ”ë¡œì›Œ: {profile['followers']})")
                return profile
            else:
                logger.warning(f"âš ï¸ í”„ë¡œí•„ ë°ì´í„° ë¶ˆì™„ì „ - username: {extracted_username}, full_name: {extracted_full_name}, followers: {profile['followers']}")
                return None
                
        except Exception as e:
            logger.error(f"í”„ë¡œí•„ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _is_post_item(self, item: Dict) -> bool:
        """ì•„ì´í…œì´ ì¼ë°˜ ê²Œì‹œë¬¼ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        if not isinstance(item, dict):
            return False
        media_type = item.get("media_type", "").lower()
        content_type = item.get("content_type", "").lower()
        return media_type in ["image", "photo", "carousel"] or content_type == "post" or "post" in str(item.get("url", ""))
    
    def _is_reel_item(self, item: Dict) -> bool:
        """ì•„ì´í…œì´ ë¦´ìŠ¤ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
        if not isinstance(item, dict):
            return False
        
        # BrightData ë¦´ìŠ¤ íŠ¹ì„± í™•ì¸
        # 1. video_play_countë‚˜ views í•„ë“œê°€ ìˆìœ¼ë©´ ë¦´ìŠ¤
        if item.get("video_play_count") or item.get("views"):
            return True
            
        # 2. description í•„ë“œê°€ ìˆê³  likes, num_commentsê°€ ìˆìœ¼ë©´ ë¦´ìŠ¤ (BrightData êµ¬ì¡°)
        if (item.get("description") and 
            (item.get("likes") is not None or item.get("num_comments") is not None) and
            item.get("user_posted")):
            return True
            
        # 3. ê¸°ì¡´ ë¡œì§ë„ ìœ ì§€
        media_type = item.get("media_type", "").lower()
        content_type = item.get("content_type", "").lower()
        return media_type == "video" or content_type == "reel" or "reel" in str(item.get("url", ""))
    
    def _extract_post_from_item(self, item: Dict, username: str) -> Optional[Dict]:
        """ì•„ì´í…œì—ì„œ ê²Œì‹œë¬¼ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        try:
            # ë°ì´í„° íƒ€ì… ê²€ì¦
            if not isinstance(item, dict):
                logger.warning(f"âš ï¸ ê²Œì‹œë¬¼ ì¶”ì¶œ ìŠ¤í‚µ: ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ë°ì´í„° íƒ€ì… {type(item)}")
                return None
            # ë” í¬ê´„ì ì¸ í•„ë“œ ë§¤í•‘ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
            def get_field_value(item, *field_names):
                for field in field_names:
                    if field in item and item[field]:
                        return item[field]
                return None
            
            post_id = get_field_value(item, "id", "shortcode", "post_id", "pk") or f"{username}_post_{hash(str(item))}"
            caption = get_field_value(item, "caption", "text", "description", "edge_media_to_caption")
            
            # edge_media_to_caption êµ¬ì¡° ì²˜ë¦¬ (Instagram Graph API í˜•ì‹)
            if isinstance(caption, dict) and "edges" in caption:
                if caption["edges"] and len(caption["edges"]) > 0:
                    caption = caption["edges"][0].get("node", {}).get("text", "")
                else:
                    caption = ""
            
            post = {
                "post_id": post_id,
                "id": post_id,  # API í˜¸í™˜ì„±ì„ ìœ„í•´ ì¶”ê°€
                "media_type": get_field_value(item, "media_type", "__typename") or "IMAGE",
                "media_urls": self._extract_media_urls(item),
                "caption": caption or "",
                "timestamp": get_field_value(item, "timestamp", "taken_at", "taken_at_timestamp", "date_posted"),
                "user_posted": get_field_value(item, "user_posted", "username", "owner") or username,
                "profile_url": get_field_value(item, "profile_url") or f"https://instagram.com/{username}",
                "date_posted": get_field_value(item, "date_posted", "date", "taken_at"),
                "num_comments": self._safe_int(get_field_value(item, "comment_count", "comments_count", "num_comments", "edge_media_to_comment")),
                "likes": self._safe_int(get_field_value(item, "like_count", "likes_count", "likes", "edge_liked_by")),
                "photos": self._extract_media_urls(item),
                "content_type": "post",
                "description": caption or "",
                "hashtags": self._extract_hashtags(caption or "")
            }
            
            # edge_media_to_comment, edge_liked_by êµ¬ì¡° ì²˜ë¦¬ (Instagram Graph API)
            if isinstance(post["num_comments"], dict) and "count" in post["num_comments"]:
                post["num_comments"] = post["num_comments"]["count"]
            if isinstance(post["likes"], dict) and "count" in post["likes"]:
                post["likes"] = post["likes"]["count"]
            
            logger.debug(f"ê²Œì‹œë¬¼ ì¶”ì¶œ: {post_id} - {post.get('media_type', 'UNKNOWN')}")
            return post
                
        except Exception as e:
            logger.error(f"ê²Œì‹œë¬¼ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)} - Item keys: {list(item.keys()) if item else 'None'}")
            return None
    
    def _extract_reel_from_item(self, item: Dict, username: str) -> Optional[Dict]:
        """ì•„ì´í…œì—ì„œ ë¦´ìŠ¤ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        try:
            # ë°ì´í„° íƒ€ì… ê²€ì¦
            if not isinstance(item, dict):
                logger.warning(f"âš ï¸ ë¦´ìŠ¤ ì¶”ì¶œ ìŠ¤í‚µ: ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹Œ ë°ì´í„° íƒ€ì… {type(item)}")
                return None
                
            # ë” í¬ê´„ì ì¸ í•„ë“œ ë§¤í•‘ì„ ìœ„í•œ í—¬í¼ í•¨ìˆ˜
            def get_field_value(item, *field_names):
                for field in field_names:
                    if field in item and item[field]:
                        return item[field]
                return None
            
            # BrightData êµ¬ì¡°ì— ë§ëŠ” ID ìƒì„± (URLì—ì„œ ì¶”ì¶œ)
            reel_url = item.get("url", "")
            if "/p/" in reel_url:
                reel_id = reel_url.split("/p/")[1].split("/")[0]
            else:
                reel_id = get_field_value(item, "id", "shortcode", "reel_id", "pk") or f"{username}_reel_{hash(str(item))}"
            
            # BrightDataëŠ” description í•„ë“œ ì‚¬ìš©
            caption = get_field_value(item, "description", "caption", "text", "edge_media_to_caption")
            
            # edge_media_to_caption êµ¬ì¡° ì²˜ë¦¬ (Instagram Graph API í˜•ì‹)
            if isinstance(caption, dict) and "edges" in caption:
                if caption["edges"] and len(caption["edges"]) > 0:
                    caption = caption["edges"][0].get("node", {}).get("text", "")
                else:
                    caption = ""
            
            thumbnail_url = get_field_value(
                item,
                "thumbnail_url",
                "thumbnail",
                "thumbnailUrl",
                "display_url",
                "cover",
                "cover_image"
            )

            media_urls = self._extract_media_urls(item)
            if thumbnail_url:
                media_urls = [thumbnail_url]

            # BrightData êµ¬ì¡°ì— ë§ëŠ” í•´ì‹œíƒœê·¸ ì²˜ë¦¬
            hashtags = item.get("hashtags", [])
            if not hashtags and caption:
                hashtags = self._extract_hashtags(caption)
            elif not isinstance(hashtags, list):
                hashtags = []
            
            reel = {
                "reel_id": reel_id,
                "id": reel_id,  # API í˜¸í™˜ì„±ì„ ìœ„í•´ ì¶”ê°€
                "media_type": "VIDEO",
                "media_urls": media_urls,
                "caption": caption or "",
                "timestamp": get_field_value(item, "date_posted", "timestamp", "taken_at", "taken_at_timestamp"),
                "user_posted": get_field_value(item, "user_posted", "username", "owner") or username,
                "profile_url": get_field_value(item, "profile_url") or f"https://instagram.com/{username}",
                "date_posted": get_field_value(item, "date_posted", "date", "taken_at"),
                "num_comments": self._safe_int(get_field_value(item, "num_comments", "comment_count", "comments_count", "edge_media_to_comment")),
                "likes": self._safe_int(get_field_value(item, "likes", "like_count", "likes_count", "edge_liked_by")),
                "photos": [],
                "content_type": "reel",
                "description": caption or "",
                "hashtags": hashtags,
                "url": get_field_value(item, "url", "permalink") or f"https://instagram.com/reel/{reel_id}",
                "views": self._safe_int(get_field_value(item, "views", "view_count", "views_count", "play_count", "video_view_count")),
                "video_play_count": self._safe_int(get_field_value(item, "video_play_count", "play_count", "views", "view_count")),
                "thumbnail_url": thumbnail_url or (media_urls[0] if media_urls else None)
            }
            
            # edge_media_to_comment, edge_liked_by êµ¬ì¡° ì²˜ë¦¬ (Instagram Graph API)
            if isinstance(reel["num_comments"], dict) and "count" in reel["num_comments"]:
                reel["num_comments"] = reel["num_comments"]["count"]
            if isinstance(reel["likes"], dict) and "count" in reel["likes"]:
                reel["likes"] = reel["likes"]["count"]
            
            logger.debug(f"ë¦´ìŠ¤ ì¶”ì¶œ: {reel_id} - Views: {reel.get('views', 0)}")
            return reel
                
        except Exception as e:
            logger.error(f"ë¦´ìŠ¤ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)} - Item keys: {list(item.keys()) if item else 'None'}")
            return None
    
    def _create_default_profile(self, username: str) -> Dict:
        """ê¸°ë³¸ í”„ë¡œí•„ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        logger.info(f"ê¸°ë³¸ í”„ë¡œí•„ ìƒì„±: {username}")
        return {
            "username": username,
            "full_name": f"{username.title()}",
            "followers": 0,
            "following": 0,
            "bio": "",
            "profile_pic_url": "",
            "account": "personal",
            "posts_count": 0,
            "avg_engagement": 0.0,
            "category_name": "",
            "profile_name": username,
            "email_address": None,
            "is_business_account": False,
            "is_professional_account": False,
            "is_verified": False
        }
    
    def _create_empty_result_with_error(self, url: str, error_msg: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ì •ë³´ì™€ í•¨ê»˜ ë¹ˆ ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        username = self._extract_username_from_url(url)
        return {
            "profile": None,
            "posts": [],
            "reels": [],
            "error": error_msg,
            "status": "collection_failed",
            "url": url
        }
    
    async def _collect_single_instagram_profile(self, session: aiohttp.ClientSession, url: str, options: Dict[str, bool] = None) -> Dict[str, Any]:
        """ë‹¨ì¼ Instagram í”„ë¡œí•„ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
        username = self._extract_username_from_url(url)
        logger.info(f"ğŸ¯ Instagram í”„ë¡œí•„ ìˆ˜ì§‘ ì‹œì‘: {username}")
        
        # 1ë‹¨ê³„: ë°ì´í„°ì…‹ ìˆ˜ì§‘ ì‘ì—… íŠ¸ë¦¬ê±°
        trigger_id = await self._trigger_dataset_collection(session, url, options)
        if not trigger_id:
            logger.error(f"ë°ì´í„°ì…‹ íŠ¸ë¦¬ê±° ì‹¤íŒ¨: {url}")
            return self._create_empty_result(url)
        
        logger.info(f"ğŸ“¡ ë°ì´í„°ì…‹ íŠ¸ë¦¬ê±° ì„±ê³µ: {trigger_id}")
        
        # 2ë‹¨ê³„: ìŠ¤ëƒ…ìƒ· ì™„ë£Œê¹Œì§€ ëŒ€ê¸° (í´ë§)
        # ë¦´ìŠ¤ ìˆ˜ì§‘ì€ ë” ì§§ì€ ëŒ€ê¸° ì‹œê°„ ì‚¬ìš©
        max_wait = 5 if 'reel' in str(options) else 10
        snapshot_data = await self._wait_for_snapshot_completion(session, trigger_id, max_wait)
        if not snapshot_data:
            logger.error(f"ìŠ¤ëƒ…ìƒ· ì™„ë£Œ ëŒ€ê¸° ì‹¤íŒ¨: {trigger_id}")
            return self._create_empty_result(url)
        
        logger.info(f"ğŸ“Š ìŠ¤ëƒ…ìƒ· ì™„ë£Œ: {len(snapshot_data)} ê°œ ë ˆì½”ë“œ")
        
        # 3ë‹¨ê³„: ë°ì´í„° íŒŒì‹± ë° êµ¬ì¡°í™”
        processed_data = self._process_instagram_snapshot(snapshot_data, username)
        
        return processed_data
    
    async def _trigger_dataset_collection(self, session: aiohttp.ClientSession, url: str, options: Dict[str, bool] = None) -> Optional[str]:
        """BrightData Dataset ìˆ˜ì§‘ ì‘ì—…ì„ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤."""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # brightdata.jsonì—ì„œ í”„ë¡œí•„ ì„¤ì • ë¡œë“œ
        import json
        from pathlib import Path
        
        config_path = Path(__file__).parent.parent.parent / "brightdata.json"
        with open(config_path, 'r', encoding='utf-8') as f:
            brightdata_config = json.load(f)
        
        # í”„ë¡œí•„ ì„¤ì •ì—ì„œ params ê°€ì ¸ì˜¤ê¸°
        profile_config = brightdata_config.get("instagram", {}).get("profile", {})
        dataset_id = profile_config.get("dataset_id")
        if not dataset_id:
            raise ValueError("profile dataset_idê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # Instagram í”„ë¡œí•„ ë°ì´í„° ìˆ˜ì§‘ì„ ìœ„í•œ ì…ë ¥ íŒŒë¼ë¯¸í„°
        payload = {
            "dataset_id": dataset_id,
            "include_errors": True,
            "format": "json",
            "notify": [],
            "input": [
                {
                    "url": url,
                    "limit_per_input": 50  # í”„ë¡œí•„ë‹¹ ìµœëŒ€ 50ê°œ ê²Œì‹œë¬¼
                }
            ]
        }
        
        # BrightData API URLs
        trigger_url = "https://api.brightdata.com/datasets/v3/trigger"
        
        logger.info(f"ğŸ“¡ Dataset íŠ¸ë¦¬ê±° ìš”ì²­: {trigger_url}")
        logger.info(f"ğŸ“¦ ìš”ì²­ í˜ì´ë¡œë“œ: {payload}")
        
        try:
            async with session.post(trigger_url, headers=headers, json=payload, timeout=30) as response:
                response_text = await response.text()
                logger.info(f"ğŸ“¨ íŠ¸ë¦¬ê±° ì‘ë‹µ ìƒíƒœ: {response.status}")
                logger.info(f"ğŸ“¨ íŠ¸ë¦¬ê±° ì‘ë‹µ: {response_text}")
                
                if response.status == 200:
                    data = await response.json()
                    trigger_id = data.get("snapshot_id")
                    if trigger_id:
                        logger.info(f"âœ… íŠ¸ë¦¬ê±° ì„±ê³µ: {trigger_id}")
                        return trigger_id
                    else:
                        logger.error(f"íŠ¸ë¦¬ê±° ì‘ë‹µì— snapshot_idê°€ ì—†ìŒ: {data}")
                        return None
                else:
                    logger.error(f"íŠ¸ë¦¬ê±° ì‹¤íŒ¨: HTTP {response.status} - {response_text}")
                    return None
                    
        except Exception as e:
            logger.error(f"íŠ¸ë¦¬ê±° ìš”ì²­ ì˜ˆì™¸: {str(e)}")
            return None
    
    async def _wait_for_snapshot_completion(self, session: aiohttp.ClientSession, trigger_id: str, max_wait_minutes: int = 15) -> Optional[List[Dict]]:
        """ìŠ¤ëƒ…ìƒ· ì™„ë£Œê¹Œì§€ ëŒ€ê¸°í•˜ê³  ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        status_url = f"https://api.brightdata.com/datasets/v3/snapshot/{trigger_id}"
        
        wait_seconds = 0
        max_wait_seconds = max_wait_minutes * 60
        check_interval = 10  # 10ì´ˆë§ˆë‹¤ ìƒíƒœ ì²´í¬
        
        logger.info(f"â³ ìŠ¤ëƒ…ìƒ· ì™„ë£Œ ëŒ€ê¸° ì¤‘... (ìµœëŒ€ {max_wait_minutes}ë¶„)")
        
        while wait_seconds < max_wait_seconds:
            try:
                async with session.get(status_url, headers=headers, timeout=30) as response:
                    if response.status == 200:
                        status_data = await response.json()
                        status = status_data.get("status")
                        
                        remaining_minutes = (max_wait_seconds - wait_seconds) // 60
                        logger.info(f"ğŸ“Š ìŠ¤ëƒ…ìƒ· ìƒíƒœ: {status} (ì•½ {remaining_minutes}ë¶„ ë‚¨ìŒ)")
                        
                        if status == "ready":
                            # ìŠ¤ëƒ…ìƒ· ì™„ë£Œ, ë°ì´í„° ë‹¤ìš´ë¡œë“œ
                            return await self._download_snapshot_data(session, trigger_id)
                        elif status == "failed" or status == "error":
                            logger.error(f"ìŠ¤ëƒ…ìƒ· ì‹¤íŒ¨: {status}")
                            return None
                        # running, pending ë“±ì˜ ê²½ìš° ê³„ì† ëŒ€ê¸°
                        
                    else:
                        logger.warning(f"ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: HTTP {response.status}")
                
                # ëŒ€ê¸°
                await asyncio.sleep(check_interval)
                wait_seconds += check_interval
                
            except Exception as e:
                logger.error(f"ìƒíƒœ í™•ì¸ ì˜ˆì™¸: {str(e)}")
                await asyncio.sleep(check_interval)
                wait_seconds += check_interval
        
        logger.error(f"ìŠ¤ëƒ…ìƒ· ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼: {max_wait_minutes}ë¶„")
        return None
    
    async def _download_snapshot_data(self, session: aiohttp.ClientSession, snapshot_id: str) -> Optional[List[Dict]]:
        """ì™„ë£Œëœ ìŠ¤ëƒ…ìƒ· ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Accept": "application/json"
        }
        
        download_url = f"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}?format=json"
        
        logger.info(f"â¬‡ï¸ ìŠ¤ëƒ…ìƒ· ë°ì´í„° ë‹¤ìš´ë¡œë“œ: {download_url}")
        
        try:
            async with session.get(download_url, headers=headers, timeout=60) as response:
                if response.status == 200:
                    # JSON Lines í˜•ì‹ìœ¼ë¡œ ë°˜í™˜ë  ìˆ˜ ìˆìŒ
                    response_text = await response.text()
                    
                    # JSON Lines íŒŒì‹±
                    data_records = []
                    for line in response_text.strip().split('\n'):
                        if line.strip():
                            try:
                                record = json.loads(line)
                                data_records.append(record)
                            except json.JSONDecodeError:
                                continue
                    
                    logger.info(f"âœ… ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(data_records)}ê°œ ë ˆì½”ë“œ")
                    return data_records
                else:
                    response_text = await response.text()
                    logger.error(f"ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: HTTP {response.status} - {response_text}")
                    return None
                    
        except Exception as e:
            logger.error(f"ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì˜ˆì™¸: {str(e)}")
            return None
    
    async def _create_test_data(self, url: str, username: str, options: Dict[str, bool] = None) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±: {username}")
        
        if not options:
            options = {"collectProfile": True, "collectPosts": True, "collectReels": True}
        
        result = {
            "profile": None,
            "posts": [],
            "reels": []
        }
        
        # í”„ë¡œí•„ ë°ì´í„° ìƒì„±
        if options.get("collectProfile", True):
            result["profile"] = {
                "username": username,
                "full_name": f"{username.title()} Test User",
                "followers": 5000 + hash(username) % 10000,
                "following": 500 + hash(username) % 500,
                "bio": f"í…ŒìŠ¤íŠ¸ ê³„ì • {username}ì…ë‹ˆë‹¤. ë§›ì§‘ê³¼ ì¼ìƒì„ ê³µìœ í•©ë‹ˆë‹¤.",
                "profile_pic_url": f"https://via.placeholder.com/150x150?text={username}",
                "account": "personal",
                "posts_count": 24,
                "avg_engagement": 3.5,
                "category_name": "Food & Lifestyle",
                "profile_name": username,
                "email_address": None,
                "is_business_account": False,
                "is_professional_account": False,
                "is_verified": False
            }
        
        # ê²Œì‹œë¬¼ ë°ì´í„° ìƒì„±
        if options.get("collectPosts", True):
            for i in range(6):  # 6ê°œ í…ŒìŠ¤íŠ¸ ê²Œì‹œë¬¼
                post = {
                    "post_id": f"{username}_post_{i+1}",
                    "media_type": "IMAGE",
                    "media_urls": [f"https://via.placeholder.com/400x400?text=Post{i+1}"],
                    "caption": f"í…ŒìŠ¤íŠ¸ ê²Œì‹œë¬¼ {i+1}ë²ˆì…ë‹ˆë‹¤. #test #instagram #{username}",
                    "timestamp": now_kst().isoformat(),
                    "user_posted": username,
                    "profile_url": f"https://instagram.com/{username}",
                    "date_posted": now_kst().strftime("%Y-%m-%d"),
                    "num_comments": 10 + (i * 5),
                    "likes": 100 + (i * 20),
                    "photos": [f"https://via.placeholder.com/400x400?text=Post{i+1}"],
                    "content_type": "post",
                    "description": f"í…ŒìŠ¤íŠ¸ ê²Œì‹œë¬¼ {i+1}ë²ˆì˜ ìƒì„¸ ì„¤ëª…ì…ë‹ˆë‹¤.",
                    "hashtags": ["#test", "#instagram", f"#{username}"]
                }
                result["posts"].append(post)
        
        # ë¦´ìŠ¤ ë°ì´í„° ìƒì„±
        if options.get("collectReels", True):
            for i in range(4):  # 4ê°œ í…ŒìŠ¤íŠ¸ ë¦´ìŠ¤
                reel = {
                    "reel_id": f"{username}_reel_{i+1}",
                    "media_type": "VIDEO", 
                    "media_urls": [f"https://via.placeholder.com/400x700?text=Reel{i+1}"],
                    "caption": f"í…ŒìŠ¤íŠ¸ ë¦´ìŠ¤ {i+1}ë²ˆì…ë‹ˆë‹¤. #reel #video #{username}",
                    "timestamp": now_kst().isoformat(),
                    "user_posted": username,
                    "profile_url": f"https://instagram.com/{username}",
                    "date_posted": now_kst().strftime("%Y-%m-%d"),
                    "num_comments": 5 + (i * 3),
                    "likes": 200 + (i * 50),
                    "photos": [],
                    "content_type": "reel",
                    "description": f"í…ŒìŠ¤íŠ¸ ë¦´ìŠ¤ {i+1}ë²ˆì˜ ìƒì„¸ ì„¤ëª…ì…ë‹ˆë‹¤.",
                    "hashtags": ["#reel", "#video", f"#{username}"],
                    "url": f"https://instagram.com/reel/{username}_reel_{i+1}",
                    "views": 1000 + (i * 200),
                    "video_play_count": 1000 + (i * 200)
                }
                result["reels"].append(reel)
        
        logger.info(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ì™„ë£Œ: í”„ë¡œí•„=1, ê²Œì‹œë¬¼={len(result['posts'])}ê°œ, ë¦´ìŠ¤={len(result['reels'])}ê°œ")
        return result
    
    def _create_empty_result(self, url: str) -> Dict[str, Any]:
        """ë¹ˆ ê²°ê³¼ êµ¬ì¡°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        username = self._extract_username_from_url(url)
        return {
            "profile": None,
            "posts": [],
            "reels": [],
            "error": "ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ - ìŠ¤ëƒ…ìƒ· ìš”ì²­ ë˜ëŠ” ëŒ€ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
            "status": "collection_failed",
            "url": url
        }
    
    def _process_instagram_snapshot(self, snapshot_data: List[Dict], username: str) -> Dict[str, Any]:
        """BrightData Instagram ìŠ¤ëƒ…ìƒ· ë°ì´í„°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        logger.info(f"ğŸ”„ Instagram ìŠ¤ëƒ…ìƒ· ë°ì´í„° ì²˜ë¦¬ ì‹œì‘: {username}, {len(snapshot_data)}ê°œ ë ˆì½”ë“œ")
        
        profile_data = None
        posts_data = []
        reels_data = []
        
        for record in snapshot_data:
            try:
                # BrightData Instagram dataset êµ¬ì¡°ì— ë”°ë¼ íŒŒì‹±
                record_type = record.get("type", "post")
                
                if record_type == "profile" or ("profile" in record and record["profile"]):
                    # í”„ë¡œí•„ ë°ì´í„° ì²˜ë¦¬
                    profile_info = record.get("profile", record)
                    profile_data = {
                        "username": username,
                        "full_name": profile_info.get("full_name") or profile_info.get("name", ""),
                        "followers": self._safe_int(profile_info.get("followers") or profile_info.get("follower_count", 0)),
                        "following": self._safe_int(profile_info.get("following") or profile_info.get("following_count", 0)),
                        "bio": profile_info.get("bio") or profile_info.get("biography", ""),
                        "profile_pic_url": profile_info.get("profile_pic_url") or profile_info.get("avatar", ""),
                        "account": profile_info.get("account_type", "personal"),
                        "posts_count": self._safe_int(profile_info.get("posts_count") or profile_info.get("media_count", 0)),
                        "avg_engagement": self._safe_float(profile_info.get("avg_engagement", 0)),
                        "category_name": profile_info.get("category", ""),
                        "profile_name": profile_info.get("profile_name", username),
                        "email_address": profile_info.get("email"),
                        "is_business_account": profile_info.get("is_business", False),
                        "is_professional_account": profile_info.get("is_professional", False),
                        "is_verified": profile_info.get("is_verified", False)
                    }
                    
                elif record_type == "reel" or record.get("media_type") == "VIDEO":
                    # ë¦´ìŠ¤ ë°ì´í„° ì²˜ë¦¬
                    reel_data = {
                        "reel_id": record.get("id") or record.get("shortcode", f"{username}_reel_{len(reels_data)+1}"),
                        "media_type": "VIDEO",
                        "media_urls": self._extract_media_urls(record),
                        "caption": record.get("caption") or record.get("text", ""),
                        "timestamp": self._parse_timestamp(record.get("taken_at") or record.get("timestamp")),
                        "user_posted": username,
                        "profile_url": f"https://instagram.com/{username}",
                        "date_posted": record.get("date", ""),
                        "num_comments": self._safe_int(record.get("comment_count") or record.get("comments", 0)),
                        "likes": self._safe_int(record.get("like_count") or record.get("likes", 0)),
                        "photos": [],
                        "content_type": "reel",
                        "description": record.get("caption") or record.get("text", ""),
                        "hashtags": self._extract_hashtags(record.get("caption", "")),
                        "url": record.get("url") or f"https://instagram.com/reel/{record.get('shortcode', '')}",
                        "views": self._safe_int(record.get("view_count") or record.get("play_count", 0)),
                        "video_play_count": self._safe_int(record.get("play_count") or record.get("view_count", 0))
                    }
                    reels_data.append(reel_data)
                    
                else:
                    # ì¼ë°˜ ê²Œì‹œë¬¼ ë°ì´í„° ì²˜ë¦¬
                    post_data = {
                        "post_id": record.get("id") or record.get("shortcode", f"{username}_post_{len(posts_data)+1}"),
                        "media_type": record.get("media_type", "IMAGE"),
                        "media_urls": self._extract_media_urls(record),
                        "caption": record.get("caption") or record.get("text", ""),
                        "timestamp": self._parse_timestamp(record.get("taken_at") or record.get("timestamp")),
                        "user_posted": username,
                        "profile_url": f"https://instagram.com/{username}",
                        "date_posted": record.get("date", ""),
                        "num_comments": self._safe_int(record.get("comment_count") or record.get("comments", 0)),
                        "likes": self._safe_int(record.get("like_count") or record.get("likes", 0)),
                        "photos": self._extract_media_urls(record),
                        "content_type": "post",
                        "description": record.get("caption") or record.get("text", ""),
                        "hashtags": self._extract_hashtags(record.get("caption", ""))
                    }
                    posts_data.append(post_data)
                    
            except Exception as e:
                logger.warning(f"ë ˆì½”ë“œ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)} - {record}")
                continue
        
        # ê¸°ë³¸ í”„ë¡œí•„ì´ ì—†ìœ¼ë©´ ìƒì„±
        if not profile_data:
            profile_data = {
                "username": username,
                "full_name": f"{username.title()}",
                "followers": 0,
                "following": 0,
                "bio": "",
                "profile_pic_url": "",
                "account": "personal",
                "posts_count": len(posts_data),
                "avg_engagement": 0.0,
                "category_name": "",
                "profile_name": username,
                "email_address": None,
                "is_business_account": False,
                "is_professional_account": False,
                "is_verified": False
            }
            # ê¸°ë³¸ í”„ë¡œí•„ë„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            try:
                saved_profile = self.influencer_service.create_or_update_profile(profile_data, username)
                logger.info(f"ğŸ’¾ ê¸°ë³¸ í”„ë¡œí•„ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ: {saved_profile.username} (ID: {saved_profile.id})")
            except Exception as db_error:
                logger.error(f"âŒ ê¸°ë³¸ í”„ë¡œí•„ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {str(db_error)}")
        
        result = {
            "profile": profile_data,
            "posts": posts_data,
            "reels": reels_data
        }
        
        logger.info(f"âœ… ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: í”„ë¡œí•„=1, ê²Œì‹œë¬¼={len(posts_data)}ê°œ, ë¦´ìŠ¤={len(reels_data)}ê°œ")
        return result
    
    def _extract_username_from_url(self, url: str) -> str:
        """Instagram URLì—ì„œ ì‚¬ìš©ìëª…ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        import re
        
        # URL ì •ë¦¬ (trailing slash ì œê±°, ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì œê±°)
        clean_url = url.strip().rstrip('/')
        if '?' in clean_url:
            clean_url = clean_url.split('?')[0]
        
        # ë‹¤ì–‘í•œ Instagram URL íŒ¨í„´ë“¤
        patterns = [
            r'(?:https?://)?(?:www\.)?instagram\.com/([a-zA-Z0-9_.]+)/?',
            r'(?:https?://)?(?:www\.)?ig\.me/([a-zA-Z0-9_.]+)/?',
            r'(?:https?://)?(?:m\.)?instagram\.com/([a-zA-Z0-9_.]+)/?'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, clean_url)
            if match:
                username = match.group(1)
                # ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ë¡œë“¤ ì œì™¸
                if username not in ['p', 'reel', 'tv', 'stories', 'explore', 'accounts']:
                    return username
        
        return "unknown_user"
    
    def _parse_timestamp(self, timestamp_str: str) -> Optional[datetime]:
        """íƒ€ì„ìŠ¤íƒ¬í”„ ë¬¸ìì—´ì„ datetime ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        if not timestamp_str:
            return None
            
        try:
            # Various timestamp formats
            formats = [
                "%Y-%m-%dT%H:%M:%S.%fZ",
                "%Y-%m-%dT%H:%M:%SZ",
                "%Y-%m-%d %H:%M:%S",
                "%Y-%m-%d"
            ]
            
            for fmt in formats:
                try:
                    return datetime.strptime(timestamp_str, fmt)
                except ValueError:
                    continue
            
            # If all formats fail, try to parse as integer timestamp
            try:
                return datetime.fromtimestamp(int(timestamp_str))
            except (ValueError, OSError):
                pass
            
            logger.warning(f"íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹± ì‹¤íŒ¨: {timestamp_str}")
            return None
            
        except Exception as e:
            logger.error(f"íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            return None
    
    def _safe_int(self, value) -> int:
        """ì•ˆì „í•˜ê²Œ ì •ìˆ˜ë¡œ ë³€í™˜"""
        if value is None:
            return 0
        try:
            return int(value)
        except (ValueError, TypeError):
            return 0
    
    def _safe_float(self, value) -> float:
        """ì•ˆì „í•˜ê²Œ ì‹¤ìˆ˜ë¡œ ë³€í™˜"""
        if value is None:
            return 0.0
        try:
            return float(value)
        except (ValueError, TypeError):
            return 0.0
    
    def _extract_media_urls(self, media_item: Dict[str, Any]) -> List[str]:
        """ë¯¸ë””ì–´ URL ì¶”ì¶œ - Instagramì˜ ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›"""
        urls = []
        
        # ë‹¤ì–‘í•œ ê°€ëŠ¥í•œ í•„ë“œëª…ë“¤
        possible_fields = [
            "media_url", "video_url", "url", "src", "display_url",
            "thumbnail_url", "display_src", "video_src",
            # Instagram Graph API í˜•ì‹
            "media_url_https", "video_url_https", "display_resources",
            # BrightData íŠ¹ìˆ˜ í˜•ì‹
            "image_url", "images", "videos", "media"
        ]
        
        for field in possible_fields:
            if field in media_item and media_item[field]:
                value = media_item[field]
                
                if isinstance(value, list):
                    # ë°°ì—´ì¸ ê²½ìš° ëª¨ë“  URL ì¶”ê°€
                    for item in value:
                        if isinstance(item, str):
                            urls.append(item)
                        elif isinstance(item, dict):
                            # display_resourcesì™€ ê°™ì€ êµ¬ì¡° ì²˜ë¦¬
                            if "src" in item:
                                urls.append(item["src"])
                            elif "url" in item:
                                urls.append(item["url"])
                elif isinstance(value, str):
                    urls.append(value)
                elif isinstance(value, dict):
                    # ì¤‘ì²©ëœ êµ¬ì¡° ì²˜ë¦¬
                    if "src" in value:
                        urls.append(value["src"])
                    elif "url" in value:
                        urls.append(value["url"])
        
        # edge_sidecar_to_children ì²˜ë¦¬ (Instagram carousel posts)
        if "edge_sidecar_to_children" in media_item:
            edges = media_item["edge_sidecar_to_children"].get("edges", [])
            for edge in edges:
                node = edge.get("node", {})
                child_urls = self._extract_media_urls(node)
                urls.extend(child_urls)
        
        # ì¤‘ë³µ ì œê±°
        unique_urls = list(dict.fromkeys(urls))  # ìˆœì„œ ìœ ì§€í•˜ë©° ì¤‘ë³µ ì œê±°
        
        if unique_urls:
            logger.debug(f"ë¯¸ë””ì–´ URL ì¶”ì¶œ ì™„ë£Œ: {len(unique_urls)}ê°œ")
        
        return unique_urls
    
    def _extract_hashtags(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í•´ì‹œíƒœê·¸ ì¶”ì¶œ"""
        if not text:
            return []
        
        import re
        hashtags = re.findall(r'#\w+', text)
        return hashtags
    
    def _extract_profile_from_brightdata(self, data: List[Dict], username: str) -> Optional[Dict]:
        """BrightData í”„ë¡œí•„ ë°ì´í„°ì—ì„œ í”„ë¡œí•„ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        try:
            for item in data:
                profile_data = self._extract_profile_from_item(item, username)
                if profile_data:
                    return profile_data
            
            # í”„ë¡œí•„ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¡œí•„ ë°˜í™˜
            return self._create_default_profile(username)
            
        except Exception as e:
            logger.error(f"í”„ë¡œí•„ ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
            return self._create_default_profile(username)
    
    def _extract_posts_from_brightdata(self, data: List[Dict], username: str) -> List[Dict]:
        """BrightData ê²Œì‹œë¬¼ ë°ì´í„°ì—ì„œ ê²Œì‹œë¬¼ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        posts = []
        
        try:
            for item in data:
                if self._is_post_item(item):
                    post = self._extract_post_from_item(item, username)
                    if post:
                        posts.append(post)
            
            logger.info(f"ê²Œì‹œë¬¼ ì¶”ì¶œ ì™„ë£Œ: {len(posts)}ê°œ")
            return posts
            
        except Exception as e:
            logger.error(f"ê²Œì‹œë¬¼ ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def _extract_reels_from_brightdata(self, data: List[Dict], username: str) -> List[Dict]:
        """BrightData ë¦´ìŠ¤ ë°ì´í„°ì—ì„œ ë¦´ìŠ¤ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        reels = []
        
        try:
            for item in data:
                if self._is_reel_item(item) or item.get("media_type") == "VIDEO":
                    reel = self._extract_reel_from_item(item, username)
                    if reel:
                        reels.append(reel)
            
            logger.info(f"ë¦´ìŠ¤ ì¶”ì¶œ ì™„ë£Œ: {len(reels)}ê°œ")
            return reels
            
        except Exception as e:
            logger.error(f"ë¦´ìŠ¤ ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def _save_snapshot_data(self, data: Any, username: str, data_type: str) -> tuple[str, str]:
        """ìŠ¤ëƒ…ìƒ· ë°ì´í„°ë¥¼ JSONê³¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = now_kst().strftime("%Y%m%d_%H%M%S")
        
        # JSON íŒŒì¼ ì €ì¥
        json_filename = f"{username}_{data_type}_{timestamp}.json"
        json_path = self.snapshot_dir / json_filename
        
        try:
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2, default=str)
            logger.info(f"ğŸ“ JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {json_path}")
        except Exception as e:
            logger.error(f"âŒ JSON íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            json_path = None
        
        # CSV íŒŒì¼ ì €ì¥ (í”Œë«í•œ ë°ì´í„°ë§Œ)
        csv_filename = f"{username}_{data_type}_{timestamp}.csv"
        csv_path = self.snapshot_dir / csv_filename
        
        try:
            csv_data = self._flatten_data_for_csv(data, data_type)
            if csv_data:
                with open(csv_path, 'w', newline='', encoding='utf-8') as f:
                    if csv_data:
                        writer = csv.DictWriter(f, fieldnames=csv_data[0].keys())
                        writer.writeheader()
                        writer.writerows(csv_data)
                logger.info(f"ğŸ“ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {csv_path}")
            else:
                csv_path = None
                logger.warning(f"âš ï¸ CSV ë³€í™˜í•  ë°ì´í„°ê°€ ì—†ìŒ: {data_type}")
        except Exception as e:
            logger.error(f"âŒ CSV íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            csv_path = None
        
        return str(json_path) if json_path else None, str(csv_path) if csv_path else None
    
    def _flatten_data_for_csv(self, data: Any, data_type: str) -> List[Dict]:
        """CSV ì €ì¥ì„ ìœ„í•´ ë°ì´í„°ë¥¼ í”Œë«í•˜ê²Œ ë³€í™˜"""
        try:
            if not data:
                return []
            
            flattened = []
            
            if isinstance(data, list):
                for item in data:
                    if isinstance(item, dict):
                        flat_item = self._flatten_dict(item)
                        flattened.append(flat_item)
            elif isinstance(data, dict):
                flat_item = self._flatten_dict(data)
                flattened.append(flat_item)
            
            return flattened
            
        except Exception as e:
            logger.error(f"âŒ CSV ë°ì´í„° ë³€í™˜ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _flatten_dict(self, d: Dict, parent_key: str = '', sep: str = '_') -> Dict:
        """ì¤‘ì²©ëœ ë”•ì…”ë„ˆë¦¬ë¥¼ í”Œë«í•˜ê²Œ ë³€í™˜"""
        items = []
        for k, v in d.items():
            new_key = f"{parent_key}{sep}{k}" if parent_key else k
            if isinstance(v, dict):
                items.extend(self._flatten_dict(v, new_key, sep=sep).items())
            elif isinstance(v, list):
                # ë¦¬ìŠ¤íŠ¸ëŠ” ë¬¸ìì—´ë¡œ ë³€í™˜
                items.append((new_key, json.dumps(v, ensure_ascii=False)))
            else:
                items.append((new_key, v))
        return dict(items)
