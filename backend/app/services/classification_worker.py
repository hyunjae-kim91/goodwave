import asyncio
import logging
import threading
from datetime import datetime, timedelta
from typing import Any, Optional

from sqlalchemy import or_
from sqlalchemy.orm import sessionmaker

from app.db.database import engine
from app.db.models import ClassificationJob
from app.services.influencer_service import InfluencerService
from app.services.openai_service import OpenAIService

logger = logging.getLogger(__name__)

KST_OFFSET = timedelta(hours=9)


def now_kst() -> datetime:
    return datetime.utcnow() + KST_OFFSET


class ClassificationWorker:
    def __init__(self) -> None:
        self.is_running = False
        self.Session = sessionmaker(bind=engine)
        self._thread: Optional[threading.Thread] = None

    async def start(self) -> None:
        if self.is_running:
            logger.info("ðŸ“¦ ë¶„ë¥˜ ì›Œì»¤ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ìž…ë‹ˆë‹¤")
            return

        self.is_running = True
        logger.info("ðŸš€ ë¶„ë¥˜ ì›Œì»¤ ì‹œìž‘")

        self.reset_orphaned_jobs()

        while self.is_running:
            try:
                processed = await self.process_next_job()
            except Exception as exc:  # noqa: BLE001
                logger.error("ë¶„ë¥˜ ì›Œì»¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: %s", exc)
                processed = False

            await asyncio.sleep(1 if processed else 5)

    def _run_forever(self) -> None:
        try:
            asyncio.run(self.start())
        except Exception as exc:  # noqa: BLE001
            logger.error("ë¶„ë¥˜ ì›Œì»¤ ìŠ¤ë ˆë“œ ì˜¤ë¥˜: %s", exc)
        finally:
            self.is_running = False
            self._thread = None

    def start_background(self) -> None:
        if self._thread and self._thread.is_alive():
            logger.info("ðŸ“¦ ë¶„ë¥˜ ì›Œì»¤ ìŠ¤ë ˆë“œê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ìž…ë‹ˆë‹¤")
            return

        self._thread = threading.Thread(target=self._run_forever, name="classification-worker", daemon=True)
        self._thread.start()

    def stop(self) -> None:
        self.is_running = False
        thread = self._thread
        if thread and thread.is_alive() and thread is not threading.current_thread():
            thread.join(timeout=5)
        self._thread = None
        logger.info("â¹ï¸ ë¶„ë¥˜ ì›Œì»¤ ì¤‘ì§€")

    def is_active(self) -> bool:
        thread = self._thread
        return bool(thread and thread.is_alive())

    def reset_orphaned_jobs(self) -> None:
        session = self.Session()
        try:
            now = now_kst()
            threshold = now - timedelta(minutes=5)
            stale_jobs = session.query(ClassificationJob).filter(
                ClassificationJob.status == "processing",
                or_(
                    ClassificationJob.started_at.is_(None),
                    ClassificationJob.started_at < threshold,
                    ClassificationJob.started_at > now
                )
            ).all()

            for job in stale_jobs:
                job.status = "pending"
                job.started_at = None
                job.completed_at = None
                job.error_message = None

            if stale_jobs:
                logger.info("ë¶„ë¥˜ ì›Œì»¤: ê³ ì•„ ìž‘ì—… %dê±´ì„ ëŒ€ê¸°ë¡œ ë˜ëŒë ¸ìŠµë‹ˆë‹¤", len(stale_jobs))
                session.commit()
        finally:
            session.close()

    async def process_next_job(self) -> bool:
        session = self.Session()
        job_id: Optional[str] = None
        try:
            job = session.query(ClassificationJob).filter(
                ClassificationJob.status == "pending"
            ).order_by(
                ClassificationJob.priority.desc(),
                ClassificationJob.created_at.asc()
            ).first()

            if not job:
                return False

            job.status = "processing"
            job.started_at = now_kst()
            session.commit()
            job_id = job.job_id
            logger.info("ðŸ”„ ë¶„ë¥˜ ìž‘ì—… ì‹œìž‘: %s (%s)", job.username, job.classification_type)
            return await self._execute_job(job_id)
        finally:
            session.close()

    async def _execute_job(self, job_id: str) -> bool:
        session = self.Session()
        try:
            job = session.query(ClassificationJob).filter(ClassificationJob.job_id == job_id).first()
            if not job:
                logger.warning("ë¶„ë¥˜ ìž‘ì—… %s ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", job_id)
                return False

            influencer_service = InfluencerService(session)
            profile = influencer_service.get_profile_by_username(job.username)
            if not profile:
                job.status = "failed"
                job.error_message = "í”„ë¡œí•„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                job.completed_at = now_kst()
                session.commit()
                logger.error("âŒ ë¶„ë¥˜ ìž‘ì—… ì‹¤íŒ¨ - í”„ë¡œí•„ ì—†ìŒ: %s", job.username)
                return True

            reels = influencer_service.get_reels_by_profile_id(profile.id)
            if not reels:
                job.status = "failed"
                job.error_message = "ë¦´ìŠ¤ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                job.completed_at = now_kst()
                session.commit()
                logger.error("âŒ ë¶„ë¥˜ ìž‘ì—… ì‹¤íŒ¨ - ë¦´ìŠ¤ ì—†ìŒ: %s", job.username)
                return True

            openai_service = OpenAIService(session)
            try:
                # ìƒˆë¡œìš´ ê°œë³„ ë¦´ìŠ¤ ê¸°ë°˜ ë¶„ë¥˜ ë°©ì‹
                if job.classification_type == "combined":
                    # êµ¬ë…ë™ê¸°ì™€ ì¹´í…Œê³ ë¦¬ë¥¼ ëª¨ë‘ ë¶„ë¥˜
                    classification_types = ["subscription_motivation", "category"]
                else:
                    # íŠ¹ì • íƒ€ìž…ë§Œ ë¶„ë¥˜
                    classification_types = [job.classification_type]

                logger.info(f"ê°œë³„ ë¦´ìŠ¤ ë¶„ë¥˜ ì‹œìž‘: {job.username}, íƒ€ìž…: {classification_types}")
                prompt_type = None
                if isinstance(job.job_metadata, dict):
                    prompt_type = job.job_metadata.get("prompt_type")
                combined_result = await openai_service.process_all_reels_for_user(
                    job.username,
                    job.id,
                    classification_types,
                    prompt_type=prompt_type,
                )

                # ì˜¤ë¥˜ í™•ì¸
                if "error" in combined_result:
                    raise Exception(combined_result["error"])
                    
            except Exception as exc:  # noqa: BLE001
                job.status = "failed"
                job.error_message = str(exc)
                job.completed_at = now_kst()
                session.commit()
                logger.error("âŒ ë¶„ë¥˜ ìž‘ì—… ì‹¤íŒ¨(OpenAI): %s - %s", job.username, exc)
                return True

            try:
                aggregated_results = combined_result.get("aggregated_results", {})

                # ì§‘ê³„ëœ ê²°ê³¼ë¥¼ ë¶„ì„ í…Œì´ë¸”ì— ì €ìž¥
                saved_payloads: dict[str, dict[str, Any]] = {}
                for aggregated_type, summary in aggregated_results.items():
                    if not summary or isinstance(summary, dict) and summary.get("error"):
                        continue
                    try:
                        influencer_service.save_analysis_result(
                            profile.id,
                            aggregated_type,
                            summary,
                            "per_reel_classification",
                        )
                        saved_payloads[aggregated_type] = summary
                    except Exception as exc:  # noqa: BLE001
                        logger.error(
                            "ì§‘ê³„ ê²°ê³¼ ì €ìž¥ ì‹¤íŒ¨(%s): %s", aggregated_type, exc
                        )

                if saved_payloads:
                    try:
                        influencer_service.save_analysis_result(
                            profile.id,
                            "combined",
                            saved_payloads,
                            "per_reel_classification",
                        )
                    except Exception as exc:  # noqa: BLE001
                        logger.error("í†µí•© ì§‘ê³„ ì €ìž¥ ì‹¤íŒ¨: %s", exc)

                job.status = "completed"
                job.completed_at = now_kst()
                job.error_message = None
                session.commit()
                
                # í†µê³„ ë¡œê¹…
                total_reels = combined_result.get("total_reels", 0)
                logger.info(
                    "âœ… ë¶„ë¥˜ ìž‘ì—… ì™„ë£Œ: %s (ë¦´ìŠ¤ %dê°œ)",
                    job.username,
                    total_reels,
                )
                return True
            except Exception as exc:  # noqa: BLE001
                session.rollback()
                job.status = "failed"
                job.error_message = str(exc)
                job.completed_at = now_kst()
                session.commit()
                logger.error("âŒ ë¶„ë¥˜ ê²°ê³¼ ì €ìž¥ ì‹¤íŒ¨: %s - %s", job.username, exc)
                return True
        finally:
            session.close()


_worker_instance: Optional[ClassificationWorker] = None


async def start_classification_worker() -> None:
    global _worker_instance
    if _worker_instance is None:
        _worker_instance = ClassificationWorker()

    if _worker_instance.is_active():
        return

    _worker_instance.start_background()


def stop_classification_worker() -> None:
    global _worker_instance
    if _worker_instance:
        _worker_instance.stop()


def get_classification_worker_status() -> dict:
    global _worker_instance
    if _worker_instance:
        return {
            "is_running": _worker_instance.is_running,
            "status": "running" if _worker_instance.is_running else "stopped",
            "thread_alive": _worker_instance.is_active(),
        }
    return {
        "is_running": False,
        "status": "not_initialized",
        "thread_alive": False,
    }
