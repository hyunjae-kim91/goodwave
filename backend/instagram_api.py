import time
import json
import requests
from dotenv import load_dotenv
import os

load_dotenv()

class Instagram:
    def __init__(self):
        """Instagram ë°ì´í„° ìˆ˜ì§‘ í´ë˜ìŠ¤ ì´ˆê¸°í™”"""
        self.api_key = os.getenv("BRIGHTDATA_API_KEY")
        if not self.api_key:
            raise ValueError("BRIGHTDATA_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def trigger_snapshot_request(self, dataset_id, params, data):
        """ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘ ìš”ì²­"""
        url = "https://api.brightdata.com/datasets/v3/trigger"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }
        # BrightData ìš”ì²­ í˜•ì‹: URL params + JSON body
        url_params = {"dataset_id": dataset_id, **params}
        response = requests.post(url, headers=headers, params=url_params, json=data)
        
        print(f"ğŸ“¡ BrightData API ì‘ë‹µ ìƒíƒœ: {response.status_code}")
        print(f"ğŸ“‹ ì‘ë‹µ í—¤ë”: {dict(response.headers)}")
        print(f"ğŸ“„ ì‘ë‹µ ë‚´ìš©: {response.text[:500]}...")  # ì²« 500ìë§Œ ì¶œë ¥
        
        # ìƒíƒœ ì½”ë“œ í™•ì¸
        if response.status_code != 200:
            print(f"âŒ BrightData API ìš”ì²­ ì‹¤íŒ¨: HTTP {response.status_code}")
            print(f"ğŸ“„ ì—ëŸ¬ ì‘ë‹µ: {response.text}")
            raise Exception(f"BrightData API ìš”ì²­ ì‹¤íŒ¨: HTTP {response.status_code} - {response.text}")

        try:
            result = response.json()
            snapshot_id = result.get("snapshot_id")
            if not snapshot_id:
                print(f"âŒ snapshot_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {result}")
                raise ValueError(f"snapshot_id not found in response: {result}")
            print(f"âœ… ìŠ¤ëƒ…ìƒ· ID ìˆ˜ì‹ : {snapshot_id}")
            return snapshot_id
        except requests.exceptions.JSONDecodeError as e:
            print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {response.text[:200]}...")
            raise Exception(f"Failed to parse trigger response as JSON. Response: {response.text[:200]}... Error: {str(e)}")

    def wait_for_snapshot(self, snapshot_id, data_type="profile", session_id=None):
        """ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘ ì™„ë£Œ ëŒ€ê¸° ë° ë°ì´í„° ìœ„ì¹˜ í™•ì¸"""
        url = f"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}"
        headers = {"Authorization": f"Bearer {self.api_key}"}
        params = {"format": "json"}

        # ë°ì´í„° íƒ€ì…ë³„ ìµœì†Œ ëŒ€ê¸° ì‹œê°„ ì„¤ì •
        if data_type in ["posts", "reels"]:
            min_wait_time = 5    # ê²Œì‹œë¬¼/ë¦´ìŠ¤ëŠ” 5ì´ˆ ëŒ€ê¸°
            max_wait_time = 600  # ë¦´ìŠ¤ëŠ” ìµœëŒ€ 10ë¶„ (600ì´ˆ)
            check_interval = 60  # 1ë¶„ ê°„ê²©
        else:
            min_wait_time = 0    # í”„ë¡œí•„ì€ ì¦‰ì‹œ í™•ì¸ ì‹œì‘
            max_wait_time = 300  # í”„ë¡œí•„ì€ ìµœëŒ€ 5ë¶„ (BrightData ì„œë²„ ë¬¸ì œ ëŒ€ì‘)
            check_interval = 10  # 10ì´ˆ ê°„ê²© (ì„œë²„ ë¶€í•˜ ì¤„ì´ê¸°)
        
        wait_count = 0
        
        # ìµœì†Œ ëŒ€ê¸° ì‹œê°„ í™•ë³´
        if min_wait_time > 0:
            print(f"ğŸ“Š {data_type.upper()} ë°ì´í„° ìˆ˜ì§‘ ì¤‘... ìµœì†Œ {min_wait_time}ì´ˆ ëŒ€ê¸°")
            if session_id:
                from app.services.progress_service import progress_service
                progress_service.update_progress(session_id, f"{data_type}_collection", 10, f"{data_type.title()} ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")
            
            time.sleep(min_wait_time)
            wait_count += min_wait_time
            
            if session_id:
                from app.services.progress_service import progress_service
                progress_service.update_progress(session_id, f"{data_type}_collection", 30, f"{data_type.title()} ë°ì´í„° ì²˜ë¦¬ ì¤‘... ({wait_count}ì´ˆ ê²½ê³¼)")
        else:
            print(f"ğŸ“Š {data_type.upper()} ë°ì´í„° ìˆ˜ì§‘ ì¤‘... ì¦‰ì‹œ ìƒíƒœ í™•ì¸ ì‹œì‘")
            if session_id:
                from app.services.progress_service import progress_service
                progress_service.update_progress(session_id, f"{data_type}_collection", 20, f"{data_type.title()} ìƒíƒœ í™•ì¸ ì‹œì‘")
        
        while wait_count < max_wait_time:
            try:
                response = requests.get(url, headers=headers, params=params)
                print(f"ğŸ“¡ {data_type.upper()} ìƒíƒœ í™•ì¸: {response.status_code} ({wait_count}ì´ˆ ê²½ê³¼)")

                if response.status_code == 202:
                    remaining_time = max_wait_time - wait_count
                    progress_percent = min(90, 30 + (wait_count - min_wait_time) * 60 / (max_wait_time - min_wait_time))
                    print(f"â³ {data_type.title()} ì²˜ë¦¬ ì¤‘... {check_interval}ì´ˆ í›„ ì¬í™•ì¸ (ë‚¨ì€ ì‹œê°„: {remaining_time}ì´ˆ)")
                    if session_id:
                        from app.services.progress_service import progress_service
                        progress_service.update_progress(session_id, f"{data_type}_collection", int(progress_percent), 
                                                       f"{data_type.title()} ë°ì´í„° ì²˜ë¦¬ ì¤‘... ({wait_count}ì´ˆ ê²½ê³¼)")
                    time.sleep(check_interval)
                    wait_count += check_interval
                    continue

                if response.status_code == 200:
                    # 200 ì‘ë‹µì¼ ë•ŒëŠ” ì™„ë£Œëœ ë°ì´í„°ê°€ ì§ì ‘ ë°˜í™˜ë¨
                    try:
                        result = response.json()
                        print(f"ğŸ” {data_type.upper()} ì‘ë‹µ êµ¬ì¡°: {type(result)}")
                        
                        if isinstance(result, list):
                            print(f"âœ… {data_type.title()} ë°ì´í„° ì§ì ‘ ë°˜í™˜ ì™„ë£Œ: {len(result)}ê°œ í•­ëª©")
                            if session_id:
                                from app.services.progress_service import progress_service
                                progress_service.update_progress(session_id, f"{data_type}_collection", 100, f"{data_type.title()} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                            return {"type": "direct_data", "data": result}
                        
                        elif isinstance(result, dict):
                            print(f"ğŸ” {data_type.upper()} ì‘ë‹µ í‚¤: {list(result.keys())}")
                            
                            # í”„ë¡œí•„ ë°ì´í„°ê°€ ì§ì ‘ ë”•ì…”ë„ˆë¦¬ë¡œ ì˜¨ ê²½ìš° (status í•„ë“œ ì—†ìŒ)
                            if data_type == "profile" and "account" in result and "followers" in result:
                                print(f"âœ… {data_type.title()} ë°ì´í„°ê°€ ì§ì ‘ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜ë¨")
                                if session_id:
                                    from app.services.progress_service import progress_service
                                    progress_service.update_progress(session_id, f"{data_type}_collection", 100, f"{data_type.title()} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                                return {"type": "direct_data", "data": [result]}  # ë¦¬ìŠ¤íŠ¸ë¡œ ë˜í•‘
                            
                            if "file_urls" in result:
                                print(f"ğŸ” file_urls íƒ€ì…: {type(result['file_urls'])}, ë‚´ìš©: {result['file_urls']}")
                            
                            # status í™•ì¸
                            status = result.get("status")
                            if status in ["done", "ready"]:
                                file_urls = result.get("file_urls", [])
                                if file_urls:
                                    print(f"âœ… {data_type.title()} íŒŒì¼ URLë¡œ ì™„ë£Œ: {len(file_urls)}ê°œ íŒŒì¼")
                                    if session_id:
                                        from app.services.progress_service import progress_service
                                        progress_service.update_progress(session_id, f"{data_type}_collection", 100, f"{data_type.title()} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                                    return {"type": "file_urls", "urls": file_urls}
                                else:
                                    # ë°ì´í„°ê°€ resultì— ì§ì ‘ ìˆì„ ìˆ˜ ìˆìŒ
                                    if "data" in result or "snapshot" in result:
                                        data_field = result.get("data") or result.get("snapshot")
                                        if data_field:
                                            print(f"âœ… {data_type.title()} ì‘ë‹µì—ì„œ ì§ì ‘ ë°ì´í„° ì¶”ì¶œ")
                                            if session_id:
                                                from app.services.progress_service import progress_service
                                                progress_service.update_progress(session_id, f"{data_type}_collection", 100, f"{data_type.title()} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                                            return {"type": "direct_data", "data": data_field}
                                    
                                    # ê¸°ë³¸ ë‹¤ìš´ë¡œë“œ URL ì‹œë„
                                    download_url = f"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}?format=json"
                                    print(f"ğŸ”— {data_type.title()} ê¸°ë³¸ ë‹¤ìš´ë¡œë“œ URL ì‚¬ìš©: {download_url}")
                                    if session_id:
                                        from app.services.progress_service import progress_service
                                        progress_service.update_progress(session_id, f"{data_type}_collection", 100, f"{data_type.title()} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                                    return {"type": "file_urls", "urls": [download_url]}
                    except Exception as e:
                        print(f"âŒ {data_type.title()} JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
                        # raw í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬ ì‹œë„
                        text_data = response.text.strip()
                        if text_data:
                            print(f"ğŸ”„ {data_type.title()} í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì²˜ë¦¬ ì‹œë„")
                            download_url = f"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}?format=json"
                            if session_id:
                                from app.services.progress_service import progress_service
                                progress_service.update_progress(session_id, f"{data_type}_collection", 100, f"{data_type.title()} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                            return {"type": "file_urls", "urls": [download_url]}

                print(f"âš ï¸ {data_type.title()} ì˜ˆìƒì¹˜ ëª»í•œ ìƒíƒœ ì½”ë“œ: {response.status_code}")
                time.sleep(check_interval)
                wait_count += check_interval
                continue

                # ê¸°íƒ€ ìƒíƒœ ì½”ë“œëŠ” ê³„ì† ëŒ€ê¸°
                remaining_time = max_wait_time - wait_count
                progress_percent = min(90, 30 + (wait_count - min_wait_time) * 60 / (max_wait_time - min_wait_time))
                print(f"â³ {data_type.title()} ì²˜ë¦¬ ì¤‘... {check_interval}ì´ˆ í›„ ì¬í™•ì¸ (ë‚¨ì€ ì‹œê°„: {remaining_time}ì´ˆ)")
                if session_id:
                    from app.services.progress_service import progress_service
                    progress_service.update_progress(session_id, f"{data_type}_collection", int(progress_percent), 
                                                   f"{data_type.title()} ë°ì´í„° ì²˜ë¦¬ ì¤‘... ({wait_count}ì´ˆ ê²½ê³¼)")
                time.sleep(check_interval)
                wait_count += check_interval
                
            except Exception as e:
                print(f"âŒ {data_type.title()} ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {e}")
                time.sleep(check_interval)
                wait_count += check_interval
        
        raise Exception(f"{data_type.title()} ìŠ¤ëƒ…ìƒ· íƒ€ì„ì•„ì›ƒ: {max_wait_time}ì´ˆ í›„")

    def download_snapshot_data(self, file_urls):
        """URL ë¦¬ìŠ¤íŠ¸ì—ì„œ JSON ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
        all_data = []
        
        # URL ìœ íš¨ì„± ê²€ì‚¬ ë° í•„í„°ë§
        valid_urls = []
        for url in file_urls:
            if isinstance(url, str) and url.startswith(('http://', 'https://')):
                valid_urls.append(url)
            else:
                print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ URL ê±´ë„ˆë›°ê¸°: {url} (íƒ€ì…: {type(url)})")
        
        if not valid_urls:
            print("âŒ ìœ íš¨í•œ URLì´ ì—†ìŠµë‹ˆë‹¤.")
            return all_data
        
        print(f"ğŸ“¥ {len(valid_urls)}ê°œì˜ ìœ íš¨í•œ URLì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘")
        
        # ì¸ì¦ í—¤ë” ì„¤ì •
        headers = {"Authorization": f"Bearer {self.api_key}"}
        
        for file_url in valid_urls:
            try:
                print(f"â¬‡ï¸ Downloading from: {file_url}")
                res = requests.get(file_url, headers=headers, timeout=30)
                res.raise_for_status()  # HTTP ì˜¤ë¥˜ ì²´í¬
                
                # Content-Type í™•ì¸
                content_type = res.headers.get('Content-Type', '')
                print(f"ğŸ“‹ Content-Type: {content_type}")
                
                if 'application/json' in content_type:
                    data = res.json()
                    
                    # ğŸ” BrightData ì‘ë‹µ ìš”ì•½ ë¡œê¹…
                    if isinstance(data, list):
                        print(f"ğŸ“Š BrightData ë¦¬ìŠ¤íŠ¸ ì‘ë‹µ: {len(data)}ê°œ í•­ëª©")
                        if len(data) > 0 and isinstance(data[0], dict):
                            print(f"   ì²« ë²ˆì§¸ í•­ëª© í‚¤ë“¤: {list(data[0].keys())}")
                            # ì¤‘ìš” í•„ë“œë§Œ ë¡œê¹…
                            if 'account' in data[0]:
                                print(f"   Account: {data[0].get('account')}")
                            if 'followers' in data[0]:
                                print(f"   Followers: {data[0].get('followers')}")
                    elif isinstance(data, dict):
                        print(f"ğŸ“Š BrightData ë”•ì…”ë„ˆë¦¬ ì‘ë‹µ: {list(data.keys())}")
                    else:
                        print(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ íƒ€ì…: {type(data)}")
                    
                    if isinstance(data, list):
                        all_data.extend(data)
                        print(f"âœ… JSON ë¦¬ìŠ¤íŠ¸ ë°ì´í„° ì¶”ê°€: {len(data)}ê°œ í•­ëª©")
                    else:
                        all_data.append(data)
                        print(f"âœ… JSON ê°ì²´ ë°ì´í„° ì¶”ê°€: 1ê°œ í•­ëª©")
                elif 'text/csv' in content_type or 'text/plain' in content_type:
                    # CSV í˜•íƒœ ì‘ë‹µ ì²˜ë¦¬
                    print(f"ğŸ“Š CSV ì‘ë‹µ ê°ì§€, CSV íŒŒì‹± ì‹œì‘")
                    csv_data = self._parse_csv_response(res.text)
                    if csv_data:
                        all_data.extend(csv_data)
                        print(f"âœ… CSV ë°ì´í„° íŒŒì‹± ì™„ë£Œ: {len(csv_data)}ê°œ í•­ëª©")
                    else:
                        print(f"âŒ CSV íŒŒì‹± ì‹¤íŒ¨")
                else:
                    # JSONì´ ì•„ë‹Œ ê²½ìš° í…ìŠ¤íŠ¸ë¡œ ì½ì–´ JSON Lines íŒŒì‹± ì‹œë„
                    text_data = res.text.strip()
                    if text_data:
                        # JSON Lines í˜•ì‹ì¼ ìˆ˜ ìˆìŒ (í•œ ì¤„ì— í•˜ë‚˜ì”© JSON)
                        for line in text_data.split('\n'):
                            line = line.strip()
                            if line:
                                try:
                                    item = json.loads(line)
                                    all_data.append(item)
                                except json.JSONDecodeError:
                                    continue
                        print(f"âœ… JSON Lines ë°ì´í„° íŒŒì‹± ì™„ë£Œ: {len(text_data.split())}ì¤„")
                    
            except requests.exceptions.RequestException as e:
                print(f"âŒ HTTP ìš”ì²­ ì‹¤íŒ¨ {file_url}: {e}")
            except ValueError as e:
                print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨ {file_url}: {e}")
            except Exception as e:
                print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ {file_url}: {e}")
        
        print(f"âœ… ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(all_data)}ê°œ í•­ëª©")
        return all_data
    
    def _parse_csv_response(self, csv_text: str):
        """CSV ì‘ë‹µì„ JSON í˜•íƒœë¡œ ë³€í™˜"""
        try:
            import csv
            import io
            import json
            
            # CSV í—¤ë”ì™€ ë°ì´í„° íŒŒì‹±
            csv_reader = csv.DictReader(io.StringIO(csv_text))
            csv_data = []
            
            for row in csv_reader:
                # ë¹ˆ ê°’ë“¤ì„ Noneìœ¼ë¡œ ë³€í™˜
                processed_row = {}
                for key, value in row.items():
                    if value == '' or value is None:
                        processed_row[key] = None
                    elif value.isdigit():
                        processed_row[key] = int(value)
                    elif value.lower() in ['true', 'false']:
                        processed_row[key] = value.lower() == 'true'
                    else:
                        # JSON ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹± ì‹œë„
                        if value and (value.startswith('[') or value.startswith('{')):
                            try:
                                processed_row[key] = json.loads(value)
                            except:
                                processed_row[key] = value
                        else:
                            processed_row[key] = value
                
                csv_data.append(processed_row)
            
            print(f"ğŸ“Š CSV íŒŒì‹± ì™„ë£Œ: {len(csv_data)}ê°œ í–‰ ì²˜ë¦¬ë¨")
            if csv_data:
                print(f"   ì²« ë²ˆì§¸ í–‰ í‚¤ë“¤: {list(csv_data[0].keys())}")
                # ì¤‘ìš” í•„ë“œ í™•ì¸
                first_row = csv_data[0]
                if 'account' in first_row:
                    print(f"   Account: {first_row.get('account')}")
                if 'followers' in first_row:
                    print(f"   Followers: {first_row.get('followers')}")
            
            return csv_data
            
        except Exception as e:
            print(f"âŒ CSV íŒŒì‹± ì—ëŸ¬: {str(e)}")
            return []

    async def get_reel_data(self, reel_url: str, config: dict) -> dict:
        """ì¸ìŠ¤íƒ€ê·¸ë¨ ë¦´ìŠ¤ URLì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. (ìº í˜ì¸ìš©)"""
        try:
            print(f"ğŸ¬ ë¦´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {reel_url}")
            
            # brightdata.jsonì—ì„œ ì„¤ì • ë¡œë“œ
            import json
            from pathlib import Path
            
            config_path = Path(__file__).parent / "brightdata.json"
            with open(config_path, 'r', encoding='utf-8') as f:
                brightdata_config = json.load(f)
            
            # ë¦´ìŠ¤ ì„¤ì •ì—ì„œ params ê°€ì ¸ì˜¤ê¸°
            reel_config = brightdata_config.get("instagram", {}).get("reel", {})
            campaign_params = reel_config.get("params", {}).copy()
            
            # ìº í˜ì¸ìš©ìœ¼ë¡œ typeê³¼ discover_by ì œê±°
            campaign_params.pop("type", None)
            campaign_params.pop("discover_by", None)
            
            # configì—ì„œ include_errors ì„¤ì • ì ìš©
            if "include_errors" in config:
                campaign_params["include_errors"] = config["include_errors"]
            
            print(f"ìº í˜ì¸ ë¦´ìŠ¤ ì„¤ì •: {campaign_params}")
            
            # ë¦´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
            dataset_id = reel_config.get("dataset_id")
            if not dataset_id:
                raise ValueError("reel dataset_idê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ìŠ¤ëƒ…ìƒ· ìš”ì²­
            snapshot_id = self.trigger_snapshot_request(
                dataset_id=dataset_id,
                params=campaign_params,
                data={"url": reel_url}
            )
            
            # ìŠ¤ëƒ…ìƒ· ì™„ë£Œ ëŒ€ê¸°
            result = self.wait_for_snapshot(snapshot_id)
            
            # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            if result["type"] == "direct_data":
                reel_data = result["data"]
                print(f"ğŸ“Š ì§ì ‘ ë°˜í™˜ëœ ë¦´ìŠ¤ ë°ì´í„°: {len(reel_data)}ê°œ í•­ëª©")
                if reel_data and len(reel_data) > 0:
                    print(f"ğŸ“‹ ì²« ë²ˆì§¸ í•­ëª© í‚¤: {list(reel_data[0].keys()) if isinstance(reel_data[0], dict) else 'Not a dict'}")
            else: # result["type"] == "file_urls"
                file_urls = result["urls"]
                reel_data = self.download_snapshot_data(file_urls)
                print(f"ğŸ“Š íŒŒì¼ì—ì„œ ë‹¤ìš´ë¡œë“œëœ ë¦´ìŠ¤ ë°ì´í„°: {len(reel_data)}ê°œ í•­ëª©")
            
            print(f"âœ… ë¦´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {reel_url}")
            return reel_data
            
        except Exception as e:
            print(f"âŒ ë¦´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            raise

    async def get_post_data(self, post_url: str, config: dict) -> dict:
        """ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œë¬¼ URLì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. (ìº í˜ì¸ìš©)"""
        try:
            print(f"ğŸ“¸ ê²Œì‹œë¬¼ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {post_url}")
            
            # brightdata.jsonì—ì„œ ì„¤ì • ë¡œë“œ
            import json
            from pathlib import Path
            
            config_path = Path(__file__).parent / "brightdata.json"
            with open(config_path, 'r', encoding='utf-8') as f:
                brightdata_config = json.load(f)
            
            # ê²Œì‹œë¬¼ ì„¤ì •ì—ì„œ params ê°€ì ¸ì˜¤ê¸°
            post_config = brightdata_config.get("instagram", {}).get("post", {})
            campaign_params = post_config.get("params", {}).copy()
            
            # ìº í˜ì¸ìš©ìœ¼ë¡œ typeê³¼ discover_by ì œê±°
            campaign_params.pop("type", None)
            campaign_params.pop("discover_by", None)
            
            # configì—ì„œ include_errors ì„¤ì • ì ìš©
            if "include_errors" in config:
                campaign_params["include_errors"] = config["include_errors"]
            
            print(f"ìº í˜ì¸ ê²Œì‹œë¬¼ ì„¤ì •: {campaign_params}")
            
            # ê²Œì‹œë¬¼ ë°ì´í„° ìˆ˜ì§‘
            dataset_id = post_config.get("dataset_id")
            if not dataset_id:
                raise ValueError("post dataset_idê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ìŠ¤ëƒ…ìƒ· ìš”ì²­
            snapshot_id = self.trigger_snapshot_request(
                dataset_id=dataset_id,
                params=campaign_params,
                data={"url": post_url}
            )
            
            # ìŠ¤ëƒ…ìƒ· ì™„ë£Œ ëŒ€ê¸°
            result = self.wait_for_snapshot(snapshot_id)
            
            # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            if result["type"] == "direct_data":
                post_data = result["data"]
                print(f"ğŸ“Š ì§ì ‘ ë°˜í™˜ëœ ê²Œì‹œë¬¼ ë°ì´í„°: {len(post_data)}ê°œ í•­ëª©")
                if post_data and len(post_data) > 0:
                    print(f"ğŸ“‹ ì²« ë²ˆì§¸ í•­ëª© í‚¤: {list(post_data[0].keys()) if isinstance(post_data[0], dict) else 'Not a dict'}")
            else: # result["type"] == "file_urls"
                file_urls = result["urls"]
                post_data = self.download_snapshot_data(file_urls)
                print(f"ğŸ“Š íŒŒì¼ì—ì„œ ë‹¤ìš´ë¡œë“œëœ ê²Œì‹œë¬¼ ë°ì´í„°: {len(post_data)}ê°œ í•­ëª©")
            
            print(f"âœ… ê²Œì‹œë¬¼ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {post_url}")
            return post_data
            
        except Exception as e:
            print(f"âŒ ê²Œì‹œë¬¼ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            raise
