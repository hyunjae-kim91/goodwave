import time
import requests
from dotenv import load_dotenv
import os

load_dotenv()

class Instagram:
    def __init__(self):
        """Instagram ë°ì´í„° ìˆ˜ì§‘ í´ë˜ìŠ¤ ì´ˆê¸°í™”"""
        self.api_key = os.getenv("BRIGHTDATA_API_KEY")
        if not self.api_key:
            raise ValueError("BRIGHTDATA_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def trigger_snapshot_request(self, dataset_id, params, data):
        """ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘ ìš”ì²­"""
        url = "https://api.brightdata.com/datasets/v3/trigger"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }
        full_params = {"dataset_id": dataset_id, **params}
        response = requests.post(url, headers=headers, params=full_params, json=data)
        
        print(f"ğŸ“¡ BrightData API ì‘ë‹µ ìƒíƒœ: {response.status_code}")
        print(f"ğŸ“‹ ì‘ë‹µ í—¤ë”: {dict(response.headers)}")
        print(f"ğŸ“„ ì‘ë‹µ ë‚´ìš©: {response.text[:500]}...")  # ì²« 500ìë§Œ ì¶œë ¥
        
        # ìƒíƒœ ì½”ë“œ í™•ì¸
        if response.status_code != 200:
            raise Exception(f"BrightData API ìš”ì²­ ì‹¤íŒ¨: HTTP {response.status_code} - {response.text}")

        try:
            result = response.json()
            snapshot_id = result.get("snapshot_id")
            if not snapshot_id:
                raise ValueError(f"snapshot_id not found in response: {result}")
            return snapshot_id
        except requests.exceptions.JSONDecodeError as e:
            raise Exception(f"Failed to parse trigger response as JSON. Response: {response.text[:200]}... Error: {str(e)}")

    def wait_for_snapshot(self, snapshot_id, data_type="profile", session_id=None):
        """ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘ ì™„ë£Œ ëŒ€ê¸° ë° ë°ì´í„° ìœ„ì¹˜ í™•ì¸"""
        url = f"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}"
        headers = {"Authorization": f"Bearer {self.api_key}"}
        params = {"format": "json"}

        # ë°ì´í„° íƒ€ì…ë³„ ìµœì†Œ ëŒ€ê¸° ì‹œê°„ ì„¤ì •
        if data_type in ["posts", "reels"]:
            min_wait_time = 120  # ê²Œì‹œë¬¼/ë¦´ìŠ¤ëŠ” ìµœì†Œ 2ë¶„
            max_wait_time = 1800 # ìµœëŒ€ 30ë¶„ (ë¬´ì œí•œì— ê°€ê¹ê²Œ)
            check_interval = 30   # 30ì´ˆ ê°„ê²©
        else:
            min_wait_time = 30   # í”„ë¡œí•„ì€ ìµœì†Œ 30ì´ˆ
            max_wait_time = 600  # ìµœëŒ€ 10ë¶„
            check_interval = 15  # 15ì´ˆ ê°„ê²©
        
        wait_count = 0
        
        # ìµœì†Œ ëŒ€ê¸° ì‹œê°„ í™•ë³´
        print(f"ğŸ“Š {data_type.upper()} ë°ì´í„° ìˆ˜ì§‘ ì¤‘... ìµœì†Œ {min_wait_time}ì´ˆ ëŒ€ê¸°")
        if session_id:
            from app.services.progress_service import progress_service
            progress_service.update_progress(session_id, f"{data_type}_collection", 10, f"{data_type.title()} ë°ì´í„° ì²˜ë¦¬ ì‹œì‘")
        
        time.sleep(min_wait_time)
        wait_count += min_wait_time
        
        if session_id:
            from app.services.progress_service import progress_service
            progress_service.update_progress(session_id, f"{data_type}_collection", 30, f"{data_type.title()} ë°ì´í„° ì²˜ë¦¬ ì¤‘... ({wait_count}ì´ˆ ê²½ê³¼)")
        
        while wait_count < max_wait_time:
            try:
                response = requests.get(url, headers=headers, params=params)
                print(f"ğŸ“¡ {data_type.upper()} ìƒíƒœ í™•ì¸: {response.status_code} ({wait_count}ì´ˆ ê²½ê³¼)")

                if response.status_code == 202:
                    remaining_time = max_wait_time - wait_count
                    progress_percent = min(90, 30 + (wait_count - min_wait_time) * 60 / (max_wait_time - min_wait_time))
                    print(f"â³ {data_type.title()} ì²˜ë¦¬ ì¤‘... {check_interval}ì´ˆ í›„ ì¬í™•ì¸ (ë‚¨ì€ ì‹œê°„: {remaining_time}ì´ˆ)")
                    if session_id:
                        from app.services.progress_service import progress_service
                        progress_service.update_progress(session_id, f"{data_type}_collection", int(progress_percent), 
                                                       f"{data_type.title()} ë°ì´í„° ì²˜ë¦¬ ì¤‘... ({wait_count}ì´ˆ ê²½ê³¼)")
                    time.sleep(check_interval)
                    wait_count += check_interval
                    continue

                if response.status_code != 200:
                    print(f"âš ï¸ {data_type.title()} ì˜ˆìƒì¹˜ ëª»í•œ ìƒíƒœ ì½”ë“œ: {response.status_code}")
                    time.sleep(check_interval)
                    wait_count += check_interval
                    continue

                result = response.json()
                print(f"ğŸ” {data_type.upper()} ì‘ë‹µ êµ¬ì¡°: {type(result)}")
                if isinstance(result, dict):
                    print(f"ğŸ” {data_type.upper()} ì‘ë‹µ í‚¤: {list(result.keys())}")
                    if "file_urls" in result:
                        print(f"ğŸ” file_urls íƒ€ì…: {type(result['file_urls'])}, ë‚´ìš©: {result['file_urls']}")

                if isinstance(result, list):
                    print(f"âœ… {data_type.title()} ë°ì´í„° ì§ì ‘ ë°˜í™˜ ì™„ë£Œ")
                    if session_id:
                        from app.services.progress_service import progress_service
                        progress_service.update_progress(session_id, f"{data_type}_collection", 100, f"{data_type.title()} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                    return {"type": "direct_data", "data": result}

                if result.get("status") == "done":
                    file_urls = result.get("file_urls", [])
                    if not file_urls:
                        raise Exception(f"{data_type.title()} ìŠ¤ëƒ…ìƒ· ì™„ë£Œë˜ì—ˆì§€ë§Œ íŒŒì¼ URLì´ ì—†ìŒ")
                    print(f"âœ… {data_type.title()} ìŠ¤ëƒ…ìƒ· ì™„ë£Œ. {len(file_urls)}ê°œ íŒŒì¼ ì‚¬ìš© ê°€ëŠ¥")
                    if session_id:
                        from app.services.progress_service import progress_service
                        progress_service.update_progress(session_id, f"{data_type}_collection", 100, f"{data_type.title()} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                    return {"type": "file_urls", "urls": file_urls}

                remaining_time = max_wait_time - wait_count
                progress_percent = min(90, 30 + (wait_count - min_wait_time) * 60 / (max_wait_time - min_wait_time))
                print(f"â³ {data_type.title()} ì²˜ë¦¬ ì¤‘... {check_interval}ì´ˆ í›„ ì¬í™•ì¸ (ë‚¨ì€ ì‹œê°„: {remaining_time}ì´ˆ)")
                if session_id:
                    from app.services.progress_service import progress_service
                    progress_service.update_progress(session_id, f"{data_type}_collection", int(progress_percent), 
                                                   f"{data_type.title()} ë°ì´í„° ì²˜ë¦¬ ì¤‘... ({wait_count}ì´ˆ ê²½ê³¼)")
                time.sleep(check_interval)
                wait_count += check_interval
                
            except Exception as e:
                print(f"âŒ {data_type.title()} ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {e}")
                time.sleep(check_interval)
                wait_count += check_interval
        
        raise Exception(f"{data_type.title()} ìŠ¤ëƒ…ìƒ· íƒ€ì„ì•„ì›ƒ: {max_wait_time}ì´ˆ í›„")

    def download_snapshot_data(self, file_urls):
        """URL ë¦¬ìŠ¤íŠ¸ì—ì„œ JSON ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
        all_data = []
        
        # URL ìœ íš¨ì„± ê²€ì‚¬ ë° í•„í„°ë§
        valid_urls = []
        for url in file_urls:
            if isinstance(url, str) and url.startswith(('http://', 'https://')):
                valid_urls.append(url)
            else:
                print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ URL ê±´ë„ˆë›°ê¸°: {url} (íƒ€ì…: {type(url)})")
        
        if not valid_urls:
            print("âŒ ìœ íš¨í•œ URLì´ ì—†ìŠµë‹ˆë‹¤.")
            return all_data
        
        print(f"ğŸ“¥ {len(valid_urls)}ê°œì˜ ìœ íš¨í•œ URLì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘")
        
        for file_url in valid_urls:
            try:
                print(f"â¬‡ï¸ Downloading from: {file_url}")
                res = requests.get(file_url)
                res.raise_for_status()  # HTTP ì˜¤ë¥˜ ì²´í¬
                
                data = res.json()
                if isinstance(data, list):
                    all_data.extend(data)
                else:
                    all_data.append(data)
                    
            except requests.exceptions.RequestException as e:
                print(f"âŒ HTTP ìš”ì²­ ì‹¤íŒ¨ {file_url}: {e}")
            except ValueError as e:
                print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨ {file_url}: {e}")
            except Exception as e:
                print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ {file_url}: {e}")
        
        print(f"âœ… ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(all_data)}ê°œ í•­ëª©")
        return all_data

    async def get_reel_data(self, reel_url: str, config: dict) -> dict:
        """ì¸ìŠ¤íƒ€ê·¸ë¨ ë¦´ìŠ¤ URLì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. (ìº í˜ì¸ìš©)"""
        try:
            print(f"ğŸ¬ ë¦´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {reel_url}")
            
            # brightdata.jsonì—ì„œ ì„¤ì • ë¡œë“œ
            import json
            from pathlib import Path
            
            config_path = Path(__file__).parent / "brightdata.json"
            with open(config_path, 'r', encoding='utf-8') as f:
                brightdata_config = json.load(f)
            
            # ë¦´ìŠ¤ ì„¤ì •ì—ì„œ params ê°€ì ¸ì˜¤ê¸°
            reel_config = brightdata_config.get("instagram", {}).get("reel", {})
            campaign_params = reel_config.get("params", {}).copy()
            
            # ìº í˜ì¸ìš©ìœ¼ë¡œ typeê³¼ discover_by ì œê±°
            campaign_params.pop("type", None)
            campaign_params.pop("discover_by", None)
            
            # configì—ì„œ include_errors ì„¤ì • ì ìš©
            if "include_errors" in config:
                campaign_params["include_errors"] = config["include_errors"]
            
            print(f"ìº í˜ì¸ ë¦´ìŠ¤ ì„¤ì •: {campaign_params}")
            
            # ë¦´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
            dataset_id = reel_config.get("dataset_id")
            if not dataset_id:
                raise ValueError("reel dataset_idê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ìŠ¤ëƒ…ìƒ· ìš”ì²­
            snapshot_id = self.trigger_snapshot_request(
                dataset_id=dataset_id,
                params=campaign_params,
                data={"url": reel_url}
            )
            
            # ìŠ¤ëƒ…ìƒ· ì™„ë£Œ ëŒ€ê¸°
            result = self.wait_for_snapshot(snapshot_id)
            
            # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            if result["type"] == "direct_data":
                reel_data = result["data"]
                print(f"ğŸ“Š ì§ì ‘ ë°˜í™˜ëœ ë¦´ìŠ¤ ë°ì´í„°: {len(reel_data)}ê°œ í•­ëª©")
                if reel_data and len(reel_data) > 0:
                    print(f"ğŸ“‹ ì²« ë²ˆì§¸ í•­ëª© í‚¤: {list(reel_data[0].keys()) if isinstance(reel_data[0], dict) else 'Not a dict'}")
            else: # result["type"] == "file_urls"
                file_urls = result["urls"]
                reel_data = self.download_snapshot_data(file_urls)
                print(f"ğŸ“Š íŒŒì¼ì—ì„œ ë‹¤ìš´ë¡œë“œëœ ë¦´ìŠ¤ ë°ì´í„°: {len(reel_data)}ê°œ í•­ëª©")
            
            print(f"âœ… ë¦´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {reel_url}")
            return reel_data
            
        except Exception as e:
            print(f"âŒ ë¦´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            raise

    async def get_post_data(self, post_url: str, config: dict) -> dict:
        """ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œë¬¼ URLì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. (ìº í˜ì¸ìš©)"""
        try:
            print(f"ğŸ“¸ ê²Œì‹œë¬¼ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {post_url}")
            
            # brightdata.jsonì—ì„œ ì„¤ì • ë¡œë“œ
            import json
            from pathlib import Path
            
            config_path = Path(__file__).parent / "brightdata.json"
            with open(config_path, 'r', encoding='utf-8') as f:
                brightdata_config = json.load(f)
            
            # ê²Œì‹œë¬¼ ì„¤ì •ì—ì„œ params ê°€ì ¸ì˜¤ê¸°
            post_config = brightdata_config.get("instagram", {}).get("post", {})
            campaign_params = post_config.get("params", {}).copy()
            
            # ìº í˜ì¸ìš©ìœ¼ë¡œ typeê³¼ discover_by ì œê±°
            campaign_params.pop("type", None)
            campaign_params.pop("discover_by", None)
            
            # configì—ì„œ include_errors ì„¤ì • ì ìš©
            if "include_errors" in config:
                campaign_params["include_errors"] = config["include_errors"]
            
            print(f"ìº í˜ì¸ ê²Œì‹œë¬¼ ì„¤ì •: {campaign_params}")
            
            # ê²Œì‹œë¬¼ ë°ì´í„° ìˆ˜ì§‘
            dataset_id = post_config.get("dataset_id")
            if not dataset_id:
                raise ValueError("post dataset_idê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ìŠ¤ëƒ…ìƒ· ìš”ì²­
            snapshot_id = self.trigger_snapshot_request(
                dataset_id=dataset_id,
                params=campaign_params,
                data={"url": post_url}
            )
            
            # ìŠ¤ëƒ…ìƒ· ì™„ë£Œ ëŒ€ê¸°
            result = self.wait_for_snapshot(snapshot_id)
            
            # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            if result["type"] == "direct_data":
                post_data = result["data"]
                print(f"ğŸ“Š ì§ì ‘ ë°˜í™˜ëœ ê²Œì‹œë¬¼ ë°ì´í„°: {len(post_data)}ê°œ í•­ëª©")
                if post_data and len(post_data) > 0:
                    print(f"ğŸ“‹ ì²« ë²ˆì§¸ í•­ëª© í‚¤: {list(post_data[0].keys()) if isinstance(post_data[0], dict) else 'Not a dict'}")
            else: # result["type"] == "file_urls"
                file_urls = result["urls"]
                post_data = self.download_snapshot_data(file_urls)
                print(f"ğŸ“Š íŒŒì¼ì—ì„œ ë‹¤ìš´ë¡œë“œëœ ê²Œì‹œë¬¼ ë°ì´í„°: {len(post_data)}ê°œ í•­ëª©")
            
            print(f"âœ… ê²Œì‹œë¬¼ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {post_url}")
            return post_data
            
        except Exception as e:
            print(f"âŒ ê²Œì‹œë¬¼ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            raise
