import time
import requests
from dotenv import load_dotenv
import os

load_dotenv()

class Instagram:
    def __init__(self):
        """Instagram ë°ì´í„° ìˆ˜ì§‘ í´ë˜ìŠ¤ ì´ˆê¸°í™”"""
        self.api_key = os.getenv("BRIGHTDATA_API_KEY")
        if not self.api_key:
            raise ValueError("BRIGHTDATA_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def trigger_snapshot_request(self, dataset_id, params, data):
        """ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘ ìš”ì²­"""
        url = "https://api.brightdata.com/datasets/v3/trigger"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }
        full_params = {"dataset_id": dataset_id, **params}
        response = requests.post(url, headers=headers, params=full_params, json=data)

        try:
            result = response.json()
            snapshot_id = result.get("snapshot_id")
            if not snapshot_id:
                raise ValueError("snapshot_id not found in response.")
            return snapshot_id
        except requests.exceptions.JSONDecodeError:
            raise Exception("Failed to parse trigger response as JSON.")

    def wait_for_snapshot(self, snapshot_id):
        """ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘ ì™„ë£Œ ëŒ€ê¸° ë° ë°ì´í„° ìœ„ì¹˜ í™•ì¸"""
        url = f"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}"
        headers = {"Authorization": f"Bearer {self.api_key}"}
        params = {"format": "json"}

        max_wait_time = 300  # ìµœëŒ€ 5ë¶„ ëŒ€ê¸°
        wait_count = 0
        
        while wait_count < max_wait_time:
            try:
                response = requests.get(url, headers=headers, params=params)
                print("Status Code:", response.status_code)

                if response.status_code == 202:
                    print("Still processing. Waiting 10 seconds...")
                    time.sleep(10)
                    wait_count += 10
                    continue

                if response.status_code != 200:
                    print(f"Unexpected status code: {response.status_code}")
                    time.sleep(10)
                    wait_count += 10
                    continue

                result = response.json()
                print(f"ğŸ” Snapshot ì‘ë‹µ êµ¬ì¡°: {type(result)}")
                if isinstance(result, dict):
                    print(f"ğŸ” Snapshot ì‘ë‹µ í‚¤: {list(result.keys())}")
                    if "file_urls" in result:
                        print(f"ğŸ” file_urls íƒ€ì…: {type(result['file_urls'])}, ë‚´ìš©: {result['file_urls']}")

                if isinstance(result, list):
                    print("Snapshot returned data directly.")
                    return {"type": "direct_data", "data": result}

                if result.get("status") == "done":
                    file_urls = result.get("file_urls", [])
                    if not file_urls:
                        raise Exception("Snapshot completed but no file URLs found.")
                    print(f"Snapshot complete. {len(file_urls)} file(s) available.")
                    print(f"ğŸ” file_urls ìƒì„¸: {file_urls}")
                    return {"type": "file_urls", "urls": file_urls}

                print("Still processing. Waiting 10 seconds...")
                time.sleep(10)
                wait_count += 10
                
            except Exception as e:
                print(f"Error while waiting for snapshot: {e}")
                time.sleep(10)
                wait_count += 10
        
        raise Exception(f"Snapshot timeout after {max_wait_time} seconds")

    def download_snapshot_data(self, file_urls):
        """URL ë¦¬ìŠ¤íŠ¸ì—ì„œ JSON ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
        all_data = []
        
        # URL ìœ íš¨ì„± ê²€ì‚¬ ë° í•„í„°ë§
        valid_urls = []
        for url in file_urls:
            if isinstance(url, str) and url.startswith(('http://', 'https://')):
                valid_urls.append(url)
            else:
                print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ URL ê±´ë„ˆë›°ê¸°: {url} (íƒ€ì…: {type(url)})")
        
        if not valid_urls:
            print("âŒ ìœ íš¨í•œ URLì´ ì—†ìŠµë‹ˆë‹¤.")
            return all_data
        
        print(f"ğŸ“¥ {len(valid_urls)}ê°œì˜ ìœ íš¨í•œ URLì—ì„œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹œì‘")
        
        for file_url in valid_urls:
            try:
                print(f"â¬‡ï¸ Downloading from: {file_url}")
                res = requests.get(file_url)
                res.raise_for_status()  # HTTP ì˜¤ë¥˜ ì²´í¬
                
                data = res.json()
                if isinstance(data, list):
                    all_data.extend(data)
                else:
                    all_data.append(data)
                    
            except requests.exceptions.RequestException as e:
                print(f"âŒ HTTP ìš”ì²­ ì‹¤íŒ¨ {file_url}: {e}")
            except ValueError as e:
                print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨ {file_url}: {e}")
            except Exception as e:
                print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ {file_url}: {e}")
        
        print(f"âœ… ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {len(all_data)}ê°œ í•­ëª©")
        return all_data

    async def get_reel_data(self, reel_url: str, config: dict) -> dict:
        """ì¸ìŠ¤íƒ€ê·¸ë¨ ë¦´ìŠ¤ URLì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. (ìº í˜ì¸ìš©)"""
        try:
            print(f"ğŸ¬ ë¦´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {reel_url}")
            
            # brightdata.jsonì—ì„œ ì„¤ì • ë¡œë“œ
            import json
            from pathlib import Path
            
            config_path = Path(__file__).parent / "backend" / "brightdata.json"
            with open(config_path, 'r', encoding='utf-8') as f:
                brightdata_config = json.load(f)
            
            # ë¦´ìŠ¤ ì„¤ì •ì—ì„œ params ê°€ì ¸ì˜¤ê¸°
            reel_config = brightdata_config.get("instagram", {}).get("reel", {})
            campaign_params = reel_config.get("params", {}).copy()
            
            # ìº í˜ì¸ìš©ìœ¼ë¡œ typeê³¼ discover_by ì œê±°
            campaign_params.pop("type", None)
            campaign_params.pop("discover_by", None)
            
            # configì—ì„œ include_errors ì„¤ì • ì ìš©
            if "include_errors" in config:
                campaign_params["include_errors"] = config["include_errors"]
            
            print(f"ìº í˜ì¸ ë¦´ìŠ¤ ì„¤ì •: {campaign_params}")
            
            # ë¦´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
            dataset_id = reel_config.get("dataset_id")
            if not dataset_id:
                raise ValueError("reel dataset_idê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ìŠ¤ëƒ…ìƒ· ìš”ì²­
            snapshot_id = self.trigger_snapshot_request(
                dataset_id=dataset_id,
                params=campaign_params,
                data={"url": reel_url}
            )
            
            # ìŠ¤ëƒ…ìƒ· ì™„ë£Œ ëŒ€ê¸°
            result = self.wait_for_snapshot(snapshot_id)
            
            # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            if result["type"] == "direct_data":
                reel_data = result["data"]
                print(f"ğŸ“Š ì§ì ‘ ë°˜í™˜ëœ ë¦´ìŠ¤ ë°ì´í„°: {len(reel_data)}ê°œ í•­ëª©")
                if reel_data and len(reel_data) > 0:
                    print(f"ğŸ“‹ ì²« ë²ˆì§¸ í•­ëª© í‚¤: {list(reel_data[0].keys()) if isinstance(reel_data[0], dict) else 'Not a dict'}")
            else: # result["type"] == "file_urls"
                file_urls = result["urls"]
                reel_data = self.download_snapshot_data(file_urls)
                print(f"ğŸ“Š íŒŒì¼ì—ì„œ ë‹¤ìš´ë¡œë“œëœ ë¦´ìŠ¤ ë°ì´í„°: {len(reel_data)}ê°œ í•­ëª©")
            
            print(f"âœ… ë¦´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {reel_url}")
            return reel_data
            
        except Exception as e:
            print(f"âŒ ë¦´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            raise

    async def get_post_data(self, post_url: str, config: dict) -> dict:
        """ì¸ìŠ¤íƒ€ê·¸ë¨ ê²Œì‹œë¬¼ URLì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤. (ìº í˜ì¸ìš©)"""
        try:
            print(f"ğŸ“¸ ê²Œì‹œë¬¼ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {post_url}")
            
            # brightdata.jsonì—ì„œ ì„¤ì • ë¡œë“œ
            import json
            from pathlib import Path
            
            config_path = Path(__file__).parent / "backend" / "brightdata.json"
            with open(config_path, 'r', encoding='utf-8') as f:
                brightdata_config = json.load(f)
            
            # ê²Œì‹œë¬¼ ì„¤ì •ì—ì„œ params ê°€ì ¸ì˜¤ê¸°
            post_config = brightdata_config.get("instagram", {}).get("post", {})
            campaign_params = post_config.get("params", {}).copy()
            
            # ìº í˜ì¸ìš©ìœ¼ë¡œ typeê³¼ discover_by ì œê±°
            campaign_params.pop("type", None)
            campaign_params.pop("discover_by", None)
            
            # configì—ì„œ include_errors ì„¤ì • ì ìš©
            if "include_errors" in config:
                campaign_params["include_errors"] = config["include_errors"]
            
            print(f"ìº í˜ì¸ ê²Œì‹œë¬¼ ì„¤ì •: {campaign_params}")
            
            # ê²Œì‹œë¬¼ ë°ì´í„° ìˆ˜ì§‘
            dataset_id = post_config.get("dataset_id")
            if not dataset_id:
                raise ValueError("post dataset_idê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            # ìŠ¤ëƒ…ìƒ· ìš”ì²­
            snapshot_id = self.trigger_snapshot_request(
                dataset_id=dataset_id,
                params=campaign_params,
                data={"url": post_url}
            )
            
            # ìŠ¤ëƒ…ìƒ· ì™„ë£Œ ëŒ€ê¸°
            result = self.wait_for_snapshot(snapshot_id)
            
            # ë°ì´í„° ë‹¤ìš´ë¡œë“œ
            if result["type"] == "direct_data":
                post_data = result["data"]
                print(f"ğŸ“Š ì§ì ‘ ë°˜í™˜ëœ ê²Œì‹œë¬¼ ë°ì´í„°: {len(post_data)}ê°œ í•­ëª©")
                if post_data and len(post_data) > 0:
                    print(f"ğŸ“‹ ì²« ë²ˆì§¸ í•­ëª© í‚¤: {list(post_data[0].keys()) if isinstance(post_data[0], dict) else 'Not a dict'}")
            else: # result["type"] == "file_urls"
                file_urls = result["urls"]
                post_data = self.download_snapshot_data(file_urls)
                print(f"ğŸ“Š íŒŒì¼ì—ì„œ ë‹¤ìš´ë¡œë“œëœ ê²Œì‹œë¬¼ ë°ì´í„°: {len(post_data)}ê°œ í•­ëª©")
            
            print(f"âœ… ê²Œì‹œë¬¼ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {post_url}")
            return post_data
            
        except Exception as e:
            print(f"âŒ ê²Œì‹œë¬¼ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}")
            raise
